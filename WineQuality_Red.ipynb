{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "General steps:\n",
        "1. Import the data\n",
        "2. info()\n",
        "3. Determine input features\n",
        "4. Determine output features\n",
        "5. Create an X array of input features\n",
        "6. Create a Y array of output features\n",
        "7. Split the data into testing and training \n",
        "8. Create the neural network model\n",
        "9. Metrics - check accuracy, loss, etc."
      ],
      "metadata": {
        "id": "5VmLZUCMeURW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ways to tune a network:\n",
        "\n",
        "\n",
        "1.   Loss\n",
        "2.   Optimizers\n",
        "3. Changing the number of neurons / nodes\n",
        "4. Change the activation function\n",
        "5. Add a layer\n",
        "\n"
      ],
      "metadata": {
        "id": "paSOWc7TeEZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ay75BaF_yQd"
      },
      "outputs": [],
      "source": [
        "# import pandas\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "white = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep = ';')\n",
        "red = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep = ';')"
      ],
      "metadata": {
        "id": "LD1PJyhcEKxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show info about white - determine which features will be inputs and which will be outputs\n",
        "white.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxFq0XOZFt4O",
        "outputId": "8d3a0cce-019d-4c0d-a64b-facf9fdc7960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4898 entries, 0 to 4897\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         4898 non-null   float64\n",
            " 1   volatile acidity      4898 non-null   float64\n",
            " 2   citric acid           4898 non-null   float64\n",
            " 3   residual sugar        4898 non-null   float64\n",
            " 4   chlorides             4898 non-null   float64\n",
            " 5   free sulfur dioxide   4898 non-null   float64\n",
            " 6   total sulfur dioxide  4898 non-null   float64\n",
            " 7   density               4898 non-null   float64\n",
            " 8   pH                    4898 non-null   float64\n",
            " 9   sulphates             4898 non-null   float64\n",
            " 10  alcohol               4898 non-null   float64\n",
            " 11  quality               4898 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 459.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show first five items in white\n",
        "white.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "oHxAqONjGElO",
        "outputId": "5e3ccae4-a35f-4249-fe2d-070882fd1011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.0              0.27         0.36            20.7      0.045   \n",
              "1            6.3              0.30         0.34             1.6      0.049   \n",
              "2            8.1              0.28         0.40             6.9      0.050   \n",
              "3            7.2              0.23         0.32             8.5      0.058   \n",
              "4            7.2              0.23         0.32             8.5      0.058   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
              "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
              "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
              "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
              "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      8.8        6  \n",
              "1      9.5        6  \n",
              "2     10.1        6  \n",
              "3      9.9        6  \n",
              "4      9.9        6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddecce46-04c3-4c7b-adfb-693176bd6ce8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.0010</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.9951</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.9956</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddecce46-04c3-4c7b-adfb-693176bd6ce8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddecce46-04c3-4c7b-adfb-693176bd6ce8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddecce46-04c3-4c7b-adfb-693176bd6ce8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show last five items in white\n",
        "white.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "j-H_4mrjGSk1",
        "outputId": "0827cc76-3f38-4ffa-95cd-5af0adb23f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "4893            6.2              0.21         0.29             1.6      0.039   \n",
              "4894            6.6              0.32         0.36             8.0      0.047   \n",
              "4895            6.5              0.24         0.19             1.2      0.041   \n",
              "4896            5.5              0.29         0.30             1.1      0.022   \n",
              "4897            6.0              0.21         0.38             0.8      0.020   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
              "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
              "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
              "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
              "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
              "\n",
              "      alcohol  quality  \n",
              "4893     11.2        6  \n",
              "4894      9.6        5  \n",
              "4895      9.4        6  \n",
              "4896     12.8        7  \n",
              "4897     11.8        6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37d16c7c-7796-46e0-844f-eafcbd5a0ab6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4893</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.039</td>\n",
              "      <td>24.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.99114</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4894</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.047</td>\n",
              "      <td>57.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4895</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.041</td>\n",
              "      <td>30.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99254</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4896</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.022</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.98869</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>12.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4897</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.020</td>\n",
              "      <td>22.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.98941</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.32</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37d16c7c-7796-46e0-844f-eafcbd5a0ab6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37d16c7c-7796-46e0-844f-eafcbd5a0ab6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37d16c7c-7796-46e0-844f-eafcbd5a0ab6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a binary version of the quality feature\n",
        "white['winequality'] = [1 if x >= 6 else 0 for x in white['quality']]"
      ],
      "metadata": {
        "id": "xSDSGLqjG0Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if our features are highly corelated\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "f, ax = plt.subplots(figsize = (10, 8))\n",
        "corr = white.corr()\n",
        "sns.heatmap(corr, mask = np.zeros_like(corr, dtype = np.bool), \n",
        "            cmap = sns.diverging_palette(220, 10, as_cmap = True), square = True, ax = ax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "n6y4jszexyGK",
        "outputId": "17346875-d0f8-4669-9476-a767ff5d3e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-7549ad3562f2>:7: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  sns.heatmap(corr, mask = np.zeros_like(corr, dtype = np.bool),\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fea5a3551f0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the info again\n",
        "white.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9NQEIztxzcS",
        "outputId": "fe6eb087-5bc2-4c03-9a8e-3d02e5ed5d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4898 entries, 0 to 4897\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         4898 non-null   float64\n",
            " 1   volatile acidity      4898 non-null   float64\n",
            " 2   citric acid           4898 non-null   float64\n",
            " 3   residual sugar        4898 non-null   float64\n",
            " 4   chlorides             4898 non-null   float64\n",
            " 5   free sulfur dioxide   4898 non-null   float64\n",
            " 6   total sulfur dioxide  4898 non-null   float64\n",
            " 7   density               4898 non-null   float64\n",
            " 8   pH                    4898 non-null   float64\n",
            " 9   sulphates             4898 non-null   float64\n",
            " 10  alcohol               4898 non-null   float64\n",
            " 11  quality               4898 non-null   int64  \n",
            " 12  winequality           4898 non-null   int64  \n",
            "dtypes: float64(11), int64(2)\n",
            "memory usage: 497.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the output values from input features, set up Y to use for classification\n",
        "X = white.drop(['quality', 'winequality', 'density', 'total sulfur dioxide', 'residual sugar'], axis = 1)\n",
        "Y = white['winequality']"
      ],
      "metadata": {
        "id": "ANBb70QnH6MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data for training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "EpMLBtOvItxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardize dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mm = MinMaxScaler()\n",
        "fit = mm.fit(X_train)\n",
        "X_train = fit.transform(X_train)\n",
        "X_test = fit.transform(X_test)"
      ],
      "metadata": {
        "id": "ml0g9y2tmt5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the neural network model\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(12, activation = 'sigmoid', input_shape = (8,)))\n",
        "model.add(Dense(8, activation = 'sigmoid'))\n",
        "model.add(Dense(4, activation = 'sigmoid'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "_mo_jtB3Jzi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model for the white wine data\n",
        "import tensorflow as tf\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.05)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "history = model.fit(X_train, Y_train, epochs = 500, batch_size = 256, verbose = 1, validation_data=(X_test, Y_test))\n",
        "\n",
        "loss, acc = model.evaluate(X_test, Y_test, verbose = 0)\n",
        "print('Test accuracy: %.3f' %acc)\n",
        "\n",
        "loss, acc = model.evaluate(X_train, Y_train, verbose = 0)\n",
        "print('Train accuracy: %.3f' %acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlHxmjeEMAcG",
        "outputId": "7ad6c1e0-2c86-4a1d-c566-e5a0cc27b65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "16/16 [==============================] - 7s 16ms/step - loss: 0.6458 - accuracy: 0.6598 - val_loss: 0.6204 - val_accuracy: 0.6867\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.6598 - val_loss: 0.6181 - val_accuracy: 0.6867\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.6152 - accuracy: 0.6598 - val_loss: 0.5582 - val_accuracy: 0.6918\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.7103 - val_loss: 0.5245 - val_accuracy: 0.7357\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7233 - val_loss: 0.5187 - val_accuracy: 0.7388\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5266 - accuracy: 0.7284 - val_loss: 0.5370 - val_accuracy: 0.7102\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7226 - val_loss: 0.5110 - val_accuracy: 0.7531\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7325 - val_loss: 0.5152 - val_accuracy: 0.7327\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5247 - accuracy: 0.7256 - val_loss: 0.5271 - val_accuracy: 0.7204\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5235 - accuracy: 0.7269 - val_loss: 0.5167 - val_accuracy: 0.7490\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.7328 - val_loss: 0.5074 - val_accuracy: 0.7541\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5183 - accuracy: 0.7363 - val_loss: 0.5122 - val_accuracy: 0.7510\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5194 - accuracy: 0.7356 - val_loss: 0.5038 - val_accuracy: 0.7541\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7351 - val_loss: 0.5052 - val_accuracy: 0.7582\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7348 - val_loss: 0.5042 - val_accuracy: 0.7531\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5134 - accuracy: 0.7407 - val_loss: 0.5002 - val_accuracy: 0.7653\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5166 - accuracy: 0.7366 - val_loss: 0.4961 - val_accuracy: 0.7643\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.7402 - val_loss: 0.4957 - val_accuracy: 0.7643\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5181 - accuracy: 0.7353 - val_loss: 0.4956 - val_accuracy: 0.7673\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.5151 - accuracy: 0.7399 - val_loss: 0.5096 - val_accuracy: 0.7398\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5152 - accuracy: 0.7420 - val_loss: 0.5045 - val_accuracy: 0.7541\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.7374 - val_loss: 0.4982 - val_accuracy: 0.7714\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5117 - accuracy: 0.7455 - val_loss: 0.4964 - val_accuracy: 0.7684\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5121 - accuracy: 0.7463 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5115 - accuracy: 0.7489 - val_loss: 0.4963 - val_accuracy: 0.7612\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5141 - accuracy: 0.7427 - val_loss: 0.5204 - val_accuracy: 0.7224\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5121 - accuracy: 0.7496 - val_loss: 0.4902 - val_accuracy: 0.7714\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5111 - accuracy: 0.7420 - val_loss: 0.4903 - val_accuracy: 0.7704\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5150 - accuracy: 0.7443 - val_loss: 0.4950 - val_accuracy: 0.7694\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5112 - accuracy: 0.7437 - val_loss: 0.4892 - val_accuracy: 0.7724\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5072 - accuracy: 0.7540 - val_loss: 0.4894 - val_accuracy: 0.7684\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5058 - accuracy: 0.7509 - val_loss: 0.4907 - val_accuracy: 0.7684\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5056 - accuracy: 0.7552 - val_loss: 0.5019 - val_accuracy: 0.7561\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5073 - accuracy: 0.7545 - val_loss: 0.4882 - val_accuracy: 0.7755\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5073 - accuracy: 0.7448 - val_loss: 0.5007 - val_accuracy: 0.7531\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.7486 - val_loss: 0.4918 - val_accuracy: 0.7714\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7509 - val_loss: 0.4923 - val_accuracy: 0.7633\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7565 - val_loss: 0.4859 - val_accuracy: 0.7704\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5087 - accuracy: 0.7483 - val_loss: 0.4881 - val_accuracy: 0.7684\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7529 - val_loss: 0.4918 - val_accuracy: 0.7673\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7573 - val_loss: 0.5279 - val_accuracy: 0.7194\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.7486 - val_loss: 0.4966 - val_accuracy: 0.7633\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5125 - accuracy: 0.7402 - val_loss: 0.4881 - val_accuracy: 0.7735\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5046 - accuracy: 0.7552 - val_loss: 0.5009 - val_accuracy: 0.7633\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7565 - val_loss: 0.4950 - val_accuracy: 0.7582\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7560 - val_loss: 0.4874 - val_accuracy: 0.7694\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5015 - accuracy: 0.7593 - val_loss: 0.4886 - val_accuracy: 0.7714\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5018 - accuracy: 0.7593 - val_loss: 0.4899 - val_accuracy: 0.7684\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7573 - val_loss: 0.4916 - val_accuracy: 0.7653\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5047 - accuracy: 0.7550 - val_loss: 0.4954 - val_accuracy: 0.7673\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7499 - val_loss: 0.4854 - val_accuracy: 0.7796\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5018 - accuracy: 0.7573 - val_loss: 0.4890 - val_accuracy: 0.7714\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7532 - val_loss: 0.4850 - val_accuracy: 0.7786\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5049 - accuracy: 0.7545 - val_loss: 0.4971 - val_accuracy: 0.7663\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7540 - val_loss: 0.4875 - val_accuracy: 0.7704\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5020 - accuracy: 0.7501 - val_loss: 0.4934 - val_accuracy: 0.7714\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7499 - val_loss: 0.4893 - val_accuracy: 0.7704\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7608 - val_loss: 0.4905 - val_accuracy: 0.7633\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4997 - accuracy: 0.7616 - val_loss: 0.4874 - val_accuracy: 0.7694\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5007 - accuracy: 0.7621 - val_loss: 0.4909 - val_accuracy: 0.7714\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.7555 - val_loss: 0.4924 - val_accuracy: 0.7633\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7601 - val_loss: 0.4853 - val_accuracy: 0.7735\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7555 - val_loss: 0.4862 - val_accuracy: 0.7673\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7619 - val_loss: 0.4910 - val_accuracy: 0.7694\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4994 - accuracy: 0.7580 - val_loss: 0.4861 - val_accuracy: 0.7694\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7631 - val_loss: 0.4896 - val_accuracy: 0.7643\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7626 - val_loss: 0.4862 - val_accuracy: 0.7704\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7624 - val_loss: 0.4850 - val_accuracy: 0.7704\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7593 - val_loss: 0.4987 - val_accuracy: 0.7520\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7519 - val_loss: 0.4921 - val_accuracy: 0.7622\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.7514 - val_loss: 0.5184 - val_accuracy: 0.7306\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5033 - accuracy: 0.7534 - val_loss: 0.4868 - val_accuracy: 0.7704\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5004 - accuracy: 0.7534 - val_loss: 0.4918 - val_accuracy: 0.7612\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7593 - val_loss: 0.4828 - val_accuracy: 0.7735\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7596 - val_loss: 0.5040 - val_accuracy: 0.7480\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7463 - val_loss: 0.4842 - val_accuracy: 0.7653\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7611 - val_loss: 0.4850 - val_accuracy: 0.7612\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7578 - val_loss: 0.4866 - val_accuracy: 0.7745\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7547 - val_loss: 0.4939 - val_accuracy: 0.7622\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7575 - val_loss: 0.4817 - val_accuracy: 0.7633\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7614 - val_loss: 0.4801 - val_accuracy: 0.7653\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.7614 - val_loss: 0.4830 - val_accuracy: 0.7582\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.7557 - val_loss: 0.4824 - val_accuracy: 0.7571\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7606 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.7644 - val_loss: 0.4808 - val_accuracy: 0.7602\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7654 - val_loss: 0.4791 - val_accuracy: 0.7663\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.7631 - val_loss: 0.4840 - val_accuracy: 0.7592\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7621 - val_loss: 0.4933 - val_accuracy: 0.7602\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7626 - val_loss: 0.4766 - val_accuracy: 0.7714\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4861 - accuracy: 0.7621 - val_loss: 0.4791 - val_accuracy: 0.7684\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7616 - val_loss: 0.4757 - val_accuracy: 0.7684\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7601 - val_loss: 0.4922 - val_accuracy: 0.7592\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7634 - val_loss: 0.4771 - val_accuracy: 0.7694\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4838 - accuracy: 0.7675 - val_loss: 0.4764 - val_accuracy: 0.7694\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7639 - val_loss: 0.4797 - val_accuracy: 0.7622\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7693 - val_loss: 0.4798 - val_accuracy: 0.7643\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4827 - accuracy: 0.7642 - val_loss: 0.4781 - val_accuracy: 0.7643\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7642 - val_loss: 0.4972 - val_accuracy: 0.7551\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.7619 - val_loss: 0.4776 - val_accuracy: 0.7765\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.7626 - val_loss: 0.4817 - val_accuracy: 0.7561\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4868 - accuracy: 0.7616 - val_loss: 0.4767 - val_accuracy: 0.7684\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7568 - val_loss: 0.4810 - val_accuracy: 0.7673\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4887 - accuracy: 0.7608 - val_loss: 0.4809 - val_accuracy: 0.7663\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.7654 - val_loss: 0.4862 - val_accuracy: 0.7633\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4854 - accuracy: 0.7621 - val_loss: 0.4899 - val_accuracy: 0.7612\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.7619 - val_loss: 0.4814 - val_accuracy: 0.7643\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4824 - accuracy: 0.7675 - val_loss: 0.4748 - val_accuracy: 0.7714\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7662 - val_loss: 0.4758 - val_accuracy: 0.7684\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4810 - accuracy: 0.7672 - val_loss: 0.4880 - val_accuracy: 0.7612\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7695 - val_loss: 0.4756 - val_accuracy: 0.7643\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4796 - accuracy: 0.7662 - val_loss: 0.4773 - val_accuracy: 0.7653\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7649 - val_loss: 0.4763 - val_accuracy: 0.7735\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4840 - accuracy: 0.7637 - val_loss: 0.4870 - val_accuracy: 0.7592\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7598 - val_loss: 0.4845 - val_accuracy: 0.7633\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4808 - accuracy: 0.7647 - val_loss: 0.4796 - val_accuracy: 0.7684\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7652 - val_loss: 0.4753 - val_accuracy: 0.7694\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7680 - val_loss: 0.4784 - val_accuracy: 0.7704\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7644 - val_loss: 0.4830 - val_accuracy: 0.7673\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7639 - val_loss: 0.4837 - val_accuracy: 0.7643\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.7682 - val_loss: 0.4764 - val_accuracy: 0.7663\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4800 - accuracy: 0.7662 - val_loss: 0.4940 - val_accuracy: 0.7592\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4851 - accuracy: 0.7649 - val_loss: 0.4786 - val_accuracy: 0.7653\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7695 - val_loss: 0.4826 - val_accuracy: 0.7653\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7682 - val_loss: 0.4745 - val_accuracy: 0.7735\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7677 - val_loss: 0.4780 - val_accuracy: 0.7663\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7626 - val_loss: 0.4812 - val_accuracy: 0.7673\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4789 - accuracy: 0.7672 - val_loss: 0.4768 - val_accuracy: 0.7602\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7657 - val_loss: 0.4801 - val_accuracy: 0.7714\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7682 - val_loss: 0.4756 - val_accuracy: 0.7704\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4758 - accuracy: 0.7713 - val_loss: 0.4794 - val_accuracy: 0.7633\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4770 - accuracy: 0.7675 - val_loss: 0.4745 - val_accuracy: 0.7684\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 0.7670 - val_loss: 0.4890 - val_accuracy: 0.7663\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4775 - accuracy: 0.7670 - val_loss: 0.4887 - val_accuracy: 0.7622\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4770 - accuracy: 0.7680 - val_loss: 0.4856 - val_accuracy: 0.7673\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4771 - accuracy: 0.7667 - val_loss: 0.4846 - val_accuracy: 0.7612\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4754 - accuracy: 0.7680 - val_loss: 0.4802 - val_accuracy: 0.7622\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4746 - accuracy: 0.7672 - val_loss: 0.4781 - val_accuracy: 0.7663\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.7639 - val_loss: 0.4811 - val_accuracy: 0.7663\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4745 - accuracy: 0.7695 - val_loss: 0.4776 - val_accuracy: 0.7673\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4752 - accuracy: 0.7682 - val_loss: 0.4786 - val_accuracy: 0.7643\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.7660 - val_loss: 0.4826 - val_accuracy: 0.7592\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4758 - accuracy: 0.7637 - val_loss: 0.4852 - val_accuracy: 0.7673\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.7654 - val_loss: 0.4776 - val_accuracy: 0.7653\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4749 - accuracy: 0.7718 - val_loss: 0.4803 - val_accuracy: 0.7673\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4793 - accuracy: 0.7647 - val_loss: 0.4824 - val_accuracy: 0.7673\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4755 - accuracy: 0.7713 - val_loss: 0.4846 - val_accuracy: 0.7622\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4788 - accuracy: 0.7670 - val_loss: 0.4768 - val_accuracy: 0.7684\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7644 - val_loss: 0.4807 - val_accuracy: 0.7765\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7649 - val_loss: 0.4802 - val_accuracy: 0.7653\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7705 - val_loss: 0.4773 - val_accuracy: 0.7694\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4792 - accuracy: 0.7677 - val_loss: 0.4837 - val_accuracy: 0.7622\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.7665 - val_loss: 0.4887 - val_accuracy: 0.7592\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4757 - accuracy: 0.7672 - val_loss: 0.4776 - val_accuracy: 0.7643\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7682 - val_loss: 0.4870 - val_accuracy: 0.7643\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7685 - val_loss: 0.4764 - val_accuracy: 0.7673\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7675 - val_loss: 0.4780 - val_accuracy: 0.7735\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.7677 - val_loss: 0.4795 - val_accuracy: 0.7622\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7680 - val_loss: 0.4781 - val_accuracy: 0.7724\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7680 - val_loss: 0.4816 - val_accuracy: 0.7582\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7713 - val_loss: 0.4817 - val_accuracy: 0.7602\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7654 - val_loss: 0.4893 - val_accuracy: 0.7653\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4767 - accuracy: 0.7703 - val_loss: 0.4793 - val_accuracy: 0.7663\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7670 - val_loss: 0.4894 - val_accuracy: 0.7643\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4747 - accuracy: 0.7654 - val_loss: 0.4846 - val_accuracy: 0.7653\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7703 - val_loss: 0.4771 - val_accuracy: 0.7776\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4735 - accuracy: 0.7662 - val_loss: 0.4876 - val_accuracy: 0.7765\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7680 - val_loss: 0.4875 - val_accuracy: 0.7663\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7665 - val_loss: 0.4933 - val_accuracy: 0.7561\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4733 - accuracy: 0.7677 - val_loss: 0.4780 - val_accuracy: 0.7653\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7682 - val_loss: 0.4803 - val_accuracy: 0.7816\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4767 - accuracy: 0.7680 - val_loss: 0.4779 - val_accuracy: 0.7714\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.7711 - val_loss: 0.4783 - val_accuracy: 0.7684\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7703 - val_loss: 0.4810 - val_accuracy: 0.7602\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7721 - val_loss: 0.4788 - val_accuracy: 0.7735\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7670 - val_loss: 0.4795 - val_accuracy: 0.7745\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7700 - val_loss: 0.4835 - val_accuracy: 0.7633\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7685 - val_loss: 0.4782 - val_accuracy: 0.7735\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4706 - accuracy: 0.7716 - val_loss: 0.4817 - val_accuracy: 0.7571\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7685 - val_loss: 0.4801 - val_accuracy: 0.7694\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4719 - accuracy: 0.7703 - val_loss: 0.4853 - val_accuracy: 0.7582\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4700 - accuracy: 0.7746 - val_loss: 0.4814 - val_accuracy: 0.7643\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7703 - val_loss: 0.4826 - val_accuracy: 0.7643\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7667 - val_loss: 0.4858 - val_accuracy: 0.7602\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.7665 - val_loss: 0.4828 - val_accuracy: 0.7612\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.7716 - val_loss: 0.4809 - val_accuracy: 0.7653\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7728 - val_loss: 0.4837 - val_accuracy: 0.7592\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4716 - accuracy: 0.7705 - val_loss: 0.4854 - val_accuracy: 0.7582\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7670 - val_loss: 0.4907 - val_accuracy: 0.7663\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7734 - val_loss: 0.4837 - val_accuracy: 0.7622\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7726 - val_loss: 0.4820 - val_accuracy: 0.7602\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7685 - val_loss: 0.4816 - val_accuracy: 0.7765\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7705 - val_loss: 0.4907 - val_accuracy: 0.7643\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7652 - val_loss: 0.4808 - val_accuracy: 0.7714\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7670 - val_loss: 0.4820 - val_accuracy: 0.7796\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4749 - accuracy: 0.7649 - val_loss: 0.4927 - val_accuracy: 0.7684\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7685 - val_loss: 0.4792 - val_accuracy: 0.7673\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7716 - val_loss: 0.4803 - val_accuracy: 0.7673\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4690 - accuracy: 0.7688 - val_loss: 0.4802 - val_accuracy: 0.7653\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7716 - val_loss: 0.4825 - val_accuracy: 0.7622\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4673 - accuracy: 0.7746 - val_loss: 0.4856 - val_accuracy: 0.7571\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.7731 - val_loss: 0.4822 - val_accuracy: 0.7816\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7744 - val_loss: 0.4825 - val_accuracy: 0.7602\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7698 - val_loss: 0.4917 - val_accuracy: 0.7735\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7711 - val_loss: 0.4854 - val_accuracy: 0.7837\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7698 - val_loss: 0.4951 - val_accuracy: 0.7827\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7667 - val_loss: 0.4873 - val_accuracy: 0.7694\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7680 - val_loss: 0.4823 - val_accuracy: 0.7612\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7721 - val_loss: 0.4978 - val_accuracy: 0.7673\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7769 - val_loss: 0.4934 - val_accuracy: 0.7694\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4824 - val_accuracy: 0.7724\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.7670 - val_loss: 0.4891 - val_accuracy: 0.7643\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4673 - accuracy: 0.7708 - val_loss: 0.4869 - val_accuracy: 0.7684\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7721 - val_loss: 0.4864 - val_accuracy: 0.7622\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4661 - accuracy: 0.7711 - val_loss: 0.4866 - val_accuracy: 0.7622\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7698 - val_loss: 0.4850 - val_accuracy: 0.7622\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.7716 - val_loss: 0.4838 - val_accuracy: 0.7602\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7688 - val_loss: 0.4817 - val_accuracy: 0.7694\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4914 - val_accuracy: 0.7704\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4665 - accuracy: 0.7716 - val_loss: 0.4887 - val_accuracy: 0.7653\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7736 - val_loss: 0.4829 - val_accuracy: 0.7765\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7711 - val_loss: 0.4875 - val_accuracy: 0.7633\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7708 - val_loss: 0.4872 - val_accuracy: 0.7633\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4676 - accuracy: 0.7754 - val_loss: 0.4798 - val_accuracy: 0.7776\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7693 - val_loss: 0.4928 - val_accuracy: 0.7592\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.7685 - val_loss: 0.4928 - val_accuracy: 0.7653\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4666 - accuracy: 0.7713 - val_loss: 0.4840 - val_accuracy: 0.7592\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4660 - accuracy: 0.7731 - val_loss: 0.4817 - val_accuracy: 0.7714\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7700 - val_loss: 0.4869 - val_accuracy: 0.7612\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.7744 - val_loss: 0.4798 - val_accuracy: 0.7765\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4652 - accuracy: 0.7698 - val_loss: 0.4818 - val_accuracy: 0.7704\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.7762 - val_loss: 0.4960 - val_accuracy: 0.7684\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.7718 - val_loss: 0.4825 - val_accuracy: 0.7776\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4643 - accuracy: 0.7751 - val_loss: 0.4831 - val_accuracy: 0.7653\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4658 - accuracy: 0.7777 - val_loss: 0.4839 - val_accuracy: 0.7714\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4652 - accuracy: 0.7700 - val_loss: 0.4825 - val_accuracy: 0.7735\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4733 - accuracy: 0.7723 - val_loss: 0.4821 - val_accuracy: 0.7714\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7657 - val_loss: 0.4944 - val_accuracy: 0.7684\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4717 - accuracy: 0.7685 - val_loss: 0.5056 - val_accuracy: 0.7643\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4695 - accuracy: 0.7708 - val_loss: 0.4800 - val_accuracy: 0.7745\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4693 - accuracy: 0.7728 - val_loss: 0.4808 - val_accuracy: 0.7735\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4630 - accuracy: 0.7731 - val_loss: 0.4869 - val_accuracy: 0.7673\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4632 - accuracy: 0.7713 - val_loss: 0.4803 - val_accuracy: 0.7765\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4683 - accuracy: 0.7711 - val_loss: 0.4969 - val_accuracy: 0.7643\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4663 - accuracy: 0.7700 - val_loss: 0.4824 - val_accuracy: 0.7735\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4692 - accuracy: 0.7713 - val_loss: 0.4807 - val_accuracy: 0.7735\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4652 - accuracy: 0.7736 - val_loss: 0.4929 - val_accuracy: 0.7633\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4651 - accuracy: 0.7731 - val_loss: 0.4834 - val_accuracy: 0.7633\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4612 - accuracy: 0.7744 - val_loss: 0.4841 - val_accuracy: 0.7633\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4613 - accuracy: 0.7762 - val_loss: 0.4824 - val_accuracy: 0.7724\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4644 - accuracy: 0.7731 - val_loss: 0.4873 - val_accuracy: 0.7633\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7612\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4617 - accuracy: 0.7749 - val_loss: 0.4819 - val_accuracy: 0.7694\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4632 - accuracy: 0.7736 - val_loss: 0.4819 - val_accuracy: 0.7724\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4620 - accuracy: 0.7721 - val_loss: 0.4831 - val_accuracy: 0.7714\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7695 - val_loss: 0.4920 - val_accuracy: 0.7602\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4643 - accuracy: 0.7764 - val_loss: 0.4845 - val_accuracy: 0.7776\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.7759 - val_loss: 0.4887 - val_accuracy: 0.7643\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4605 - accuracy: 0.7744 - val_loss: 0.4845 - val_accuracy: 0.7643\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4599 - accuracy: 0.7757 - val_loss: 0.4992 - val_accuracy: 0.7694\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4618 - accuracy: 0.7757 - val_loss: 0.4937 - val_accuracy: 0.7602\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.7739 - val_loss: 0.4860 - val_accuracy: 0.7612\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7744 - val_loss: 0.4904 - val_accuracy: 0.7612\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4640 - accuracy: 0.7726 - val_loss: 0.4842 - val_accuracy: 0.7724\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.7744 - val_loss: 0.4847 - val_accuracy: 0.7714\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4617 - accuracy: 0.7769 - val_loss: 0.4864 - val_accuracy: 0.7684\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4618 - accuracy: 0.7741 - val_loss: 0.4852 - val_accuracy: 0.7684\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4868 - val_accuracy: 0.7653\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7762 - val_loss: 0.4851 - val_accuracy: 0.7694\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4603 - accuracy: 0.7739 - val_loss: 0.4862 - val_accuracy: 0.7745\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4660 - accuracy: 0.7746 - val_loss: 0.4995 - val_accuracy: 0.7714\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7769 - val_loss: 0.4936 - val_accuracy: 0.7663\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7751 - val_loss: 0.4854 - val_accuracy: 0.7765\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4616 - accuracy: 0.7741 - val_loss: 0.4867 - val_accuracy: 0.7694\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4579 - accuracy: 0.7749 - val_loss: 0.4858 - val_accuracy: 0.7704\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4601 - accuracy: 0.7751 - val_loss: 0.4887 - val_accuracy: 0.7673\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4609 - accuracy: 0.7734 - val_loss: 0.4847 - val_accuracy: 0.7745\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7744 - val_loss: 0.4966 - val_accuracy: 0.7704\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7757 - val_loss: 0.4869 - val_accuracy: 0.7735\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7759 - val_loss: 0.4894 - val_accuracy: 0.7714\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7721 - val_loss: 0.4870 - val_accuracy: 0.7714\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4632 - accuracy: 0.7764 - val_loss: 0.5033 - val_accuracy: 0.7643\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4562 - accuracy: 0.7785 - val_loss: 0.4863 - val_accuracy: 0.7704\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4586 - accuracy: 0.7772 - val_loss: 0.4877 - val_accuracy: 0.7694\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4608 - accuracy: 0.7759 - val_loss: 0.4881 - val_accuracy: 0.7684\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4591 - accuracy: 0.7741 - val_loss: 0.4869 - val_accuracy: 0.7673\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4567 - accuracy: 0.7731 - val_loss: 0.4914 - val_accuracy: 0.7633\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7746 - val_loss: 0.4875 - val_accuracy: 0.7673\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4577 - accuracy: 0.7787 - val_loss: 0.4902 - val_accuracy: 0.7796\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4589 - accuracy: 0.7767 - val_loss: 0.4903 - val_accuracy: 0.7735\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.7777 - val_loss: 0.4904 - val_accuracy: 0.7643\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4567 - accuracy: 0.7767 - val_loss: 0.4924 - val_accuracy: 0.7673\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7739 - val_loss: 0.4881 - val_accuracy: 0.7765\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4586 - accuracy: 0.7744 - val_loss: 0.4940 - val_accuracy: 0.7653\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7751 - val_loss: 0.4902 - val_accuracy: 0.7653\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7759 - val_loss: 0.4958 - val_accuracy: 0.7694\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7746 - val_loss: 0.5000 - val_accuracy: 0.7653\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4557 - accuracy: 0.7777 - val_loss: 0.4950 - val_accuracy: 0.7643\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4561 - accuracy: 0.7746 - val_loss: 0.4913 - val_accuracy: 0.7673\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4580 - accuracy: 0.7754 - val_loss: 0.4907 - val_accuracy: 0.7602\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.7792 - val_loss: 0.4973 - val_accuracy: 0.7643\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4577 - accuracy: 0.7739 - val_loss: 0.4949 - val_accuracy: 0.7684\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4567 - accuracy: 0.7772 - val_loss: 0.4961 - val_accuracy: 0.7622\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4546 - accuracy: 0.7777 - val_loss: 0.5084 - val_accuracy: 0.7673\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7815 - val_loss: 0.4898 - val_accuracy: 0.7765\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.7744 - val_loss: 0.5202 - val_accuracy: 0.7541\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.7703 - val_loss: 0.4911 - val_accuracy: 0.7643\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7688 - val_loss: 0.4902 - val_accuracy: 0.7673\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4568 - accuracy: 0.7792 - val_loss: 0.4932 - val_accuracy: 0.7724\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7723 - val_loss: 0.4952 - val_accuracy: 0.7673\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7767 - val_loss: 0.5306 - val_accuracy: 0.7520\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4639 - accuracy: 0.7736 - val_loss: 0.4911 - val_accuracy: 0.7622\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4642 - accuracy: 0.7698 - val_loss: 0.4902 - val_accuracy: 0.7755\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7744 - val_loss: 0.4883 - val_accuracy: 0.7673\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.7782 - val_loss: 0.4954 - val_accuracy: 0.7684\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.7757 - val_loss: 0.5028 - val_accuracy: 0.7673\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.4950 - val_accuracy: 0.7735\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.7782 - val_loss: 0.4917 - val_accuracy: 0.7643\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4555 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7673\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7751 - val_loss: 0.4965 - val_accuracy: 0.7673\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7757 - val_loss: 0.4960 - val_accuracy: 0.7776\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.7777 - val_loss: 0.4930 - val_accuracy: 0.7633\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4511 - accuracy: 0.7823 - val_loss: 0.4966 - val_accuracy: 0.7735\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.7759 - val_loss: 0.5036 - val_accuracy: 0.7735\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.7785 - val_loss: 0.4929 - val_accuracy: 0.7653\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4555 - accuracy: 0.7741 - val_loss: 0.4919 - val_accuracy: 0.7612\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.7787 - val_loss: 0.5025 - val_accuracy: 0.7714\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4530 - accuracy: 0.7774 - val_loss: 0.5043 - val_accuracy: 0.7684\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4535 - accuracy: 0.7841 - val_loss: 0.4940 - val_accuracy: 0.7735\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7795 - val_loss: 0.4958 - val_accuracy: 0.7612\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7802 - val_loss: 0.4940 - val_accuracy: 0.7633\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7774 - val_loss: 0.4933 - val_accuracy: 0.7643\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7828 - val_loss: 0.4997 - val_accuracy: 0.7694\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4514 - accuracy: 0.7813 - val_loss: 0.4966 - val_accuracy: 0.7684\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.7825 - val_loss: 0.4931 - val_accuracy: 0.7735\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.7810 - val_loss: 0.4972 - val_accuracy: 0.7755\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7802 - val_loss: 0.5149 - val_accuracy: 0.7602\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4596 - accuracy: 0.7754 - val_loss: 0.5070 - val_accuracy: 0.7633\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4515 - accuracy: 0.7800 - val_loss: 0.5004 - val_accuracy: 0.7745\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4493 - accuracy: 0.7869 - val_loss: 0.4998 - val_accuracy: 0.7735\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4529 - accuracy: 0.7805 - val_loss: 0.4948 - val_accuracy: 0.7724\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4493 - accuracy: 0.7851 - val_loss: 0.4997 - val_accuracy: 0.7724\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4529 - accuracy: 0.7825 - val_loss: 0.5021 - val_accuracy: 0.7735\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4533 - accuracy: 0.7790 - val_loss: 0.4989 - val_accuracy: 0.7714\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4504 - accuracy: 0.7838 - val_loss: 0.4992 - val_accuracy: 0.7694\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4516 - accuracy: 0.7802 - val_loss: 0.4924 - val_accuracy: 0.7663\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4493 - accuracy: 0.7823 - val_loss: 0.4945 - val_accuracy: 0.7673\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.7797 - val_loss: 0.4943 - val_accuracy: 0.7714\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.7841 - val_loss: 0.4963 - val_accuracy: 0.7745\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4474 - accuracy: 0.7856 - val_loss: 0.4950 - val_accuracy: 0.7776\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4530 - accuracy: 0.7787 - val_loss: 0.4918 - val_accuracy: 0.7796\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.7879 - val_loss: 0.4930 - val_accuracy: 0.7663\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.7846 - val_loss: 0.4929 - val_accuracy: 0.7786\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4515 - accuracy: 0.7818 - val_loss: 0.5022 - val_accuracy: 0.7714\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4475 - accuracy: 0.7838 - val_loss: 0.4917 - val_accuracy: 0.7735\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4466 - accuracy: 0.7853 - val_loss: 0.5005 - val_accuracy: 0.7735\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7836 - val_loss: 0.4911 - val_accuracy: 0.7755\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.7836 - val_loss: 0.4929 - val_accuracy: 0.7694\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7859 - val_loss: 0.4900 - val_accuracy: 0.7735\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.7836 - val_loss: 0.4896 - val_accuracy: 0.7694\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7838 - val_loss: 0.4906 - val_accuracy: 0.7704\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7843 - val_loss: 0.4926 - val_accuracy: 0.7684\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7815 - val_loss: 0.4910 - val_accuracy: 0.7755\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4470 - accuracy: 0.7869 - val_loss: 0.4940 - val_accuracy: 0.7745\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.7853 - val_loss: 0.4971 - val_accuracy: 0.7796\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.7874 - val_loss: 0.4970 - val_accuracy: 0.7745\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7797 - val_loss: 0.4985 - val_accuracy: 0.7806\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7831 - val_loss: 0.5064 - val_accuracy: 0.7643\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.7864 - val_loss: 0.4959 - val_accuracy: 0.7735\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.4903 - val_accuracy: 0.7735\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.7864 - val_loss: 0.4914 - val_accuracy: 0.7704\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7869 - val_loss: 0.5000 - val_accuracy: 0.7755\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4557 - accuracy: 0.7769 - val_loss: 0.4911 - val_accuracy: 0.7704\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.7836 - val_loss: 0.4900 - val_accuracy: 0.7755\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7853 - val_loss: 0.4889 - val_accuracy: 0.7714\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.7831 - val_loss: 0.5038 - val_accuracy: 0.7714\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4512 - accuracy: 0.7762 - val_loss: 0.4917 - val_accuracy: 0.7755\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4894 - val_accuracy: 0.7755\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7856 - val_loss: 0.4916 - val_accuracy: 0.7735\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7884 - val_loss: 0.5023 - val_accuracy: 0.7714\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4445 - accuracy: 0.7861 - val_loss: 0.4884 - val_accuracy: 0.7786\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4455 - accuracy: 0.7818 - val_loss: 0.4931 - val_accuracy: 0.7755\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4437 - accuracy: 0.7864 - val_loss: 0.4887 - val_accuracy: 0.7776\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7843 - val_loss: 0.4938 - val_accuracy: 0.7786\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.7859 - val_loss: 0.5134 - val_accuracy: 0.7633\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.7838 - val_loss: 0.4907 - val_accuracy: 0.7765\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4422 - accuracy: 0.7851 - val_loss: 0.4896 - val_accuracy: 0.7765\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7856 - val_loss: 0.4956 - val_accuracy: 0.7755\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7871 - val_loss: 0.4946 - val_accuracy: 0.7776\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7859 - val_loss: 0.4885 - val_accuracy: 0.7816\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.7864 - val_loss: 0.4910 - val_accuracy: 0.7857\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7879 - val_loss: 0.4927 - val_accuracy: 0.7796\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7892 - val_loss: 0.4988 - val_accuracy: 0.7653\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.7876 - val_loss: 0.4904 - val_accuracy: 0.7806\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7864 - val_loss: 0.4981 - val_accuracy: 0.7796\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7884 - val_loss: 0.5065 - val_accuracy: 0.7643\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7876 - val_loss: 0.4955 - val_accuracy: 0.7786\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4388 - accuracy: 0.7871 - val_loss: 0.4892 - val_accuracy: 0.7806\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.7871 - val_loss: 0.4903 - val_accuracy: 0.7816\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7820 - val_loss: 0.4952 - val_accuracy: 0.7714\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.7902 - val_loss: 0.4916 - val_accuracy: 0.7765\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7889 - val_loss: 0.4918 - val_accuracy: 0.7786\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.7836 - val_loss: 0.5010 - val_accuracy: 0.7622\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.7828 - val_loss: 0.4930 - val_accuracy: 0.7765\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.7861 - val_loss: 0.4954 - val_accuracy: 0.7745\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.7869 - val_loss: 0.4923 - val_accuracy: 0.7786\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4361 - accuracy: 0.7876 - val_loss: 0.4917 - val_accuracy: 0.7827\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.7884 - val_loss: 0.4899 - val_accuracy: 0.7735\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.7861 - val_loss: 0.5308 - val_accuracy: 0.7633\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.7797 - val_loss: 0.4922 - val_accuracy: 0.7776\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.7856 - val_loss: 0.4975 - val_accuracy: 0.7765\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7892 - val_loss: 0.4964 - val_accuracy: 0.7786\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4391 - accuracy: 0.7833 - val_loss: 0.4997 - val_accuracy: 0.7673\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.7912 - val_loss: 0.4981 - val_accuracy: 0.7765\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.4947 - val_accuracy: 0.7776\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7894 - val_loss: 0.4982 - val_accuracy: 0.7755\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.7871 - val_loss: 0.4973 - val_accuracy: 0.7724\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4478 - accuracy: 0.7810 - val_loss: 0.5124 - val_accuracy: 0.7520\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.7841 - val_loss: 0.5002 - val_accuracy: 0.7653\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7902 - val_loss: 0.4974 - val_accuracy: 0.7663\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.7869 - val_loss: 0.4933 - val_accuracy: 0.7827\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.7902 - val_loss: 0.4980 - val_accuracy: 0.7786\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7796\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.7889 - val_loss: 0.4892 - val_accuracy: 0.7776\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.7889 - val_loss: 0.4900 - val_accuracy: 0.7796\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.7874 - val_loss: 0.4868 - val_accuracy: 0.7765\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.7905 - val_loss: 0.4957 - val_accuracy: 0.7796\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7884 - val_loss: 0.4907 - val_accuracy: 0.7796\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.4986 - val_accuracy: 0.7776\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7861 - val_loss: 0.4945 - val_accuracy: 0.7806\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7887 - val_loss: 0.4889 - val_accuracy: 0.7857\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.4888 - val_accuracy: 0.7806\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.7884 - val_loss: 0.5027 - val_accuracy: 0.7796\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.7915 - val_loss: 0.4880 - val_accuracy: 0.7847\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7943 - val_loss: 0.4921 - val_accuracy: 0.7806\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7966 - val_loss: 0.4896 - val_accuracy: 0.7867\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.7920 - val_loss: 0.5005 - val_accuracy: 0.7714\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4326 - accuracy: 0.7943 - val_loss: 0.4999 - val_accuracy: 0.7837\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4398 - accuracy: 0.7874 - val_loss: 0.4893 - val_accuracy: 0.7827\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4383 - accuracy: 0.7922 - val_loss: 0.4959 - val_accuracy: 0.7735\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4369 - accuracy: 0.7871 - val_loss: 0.4951 - val_accuracy: 0.7857\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4376 - accuracy: 0.7879 - val_loss: 0.4961 - val_accuracy: 0.7806\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4341 - accuracy: 0.7912 - val_loss: 0.4934 - val_accuracy: 0.7806\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4325 - accuracy: 0.7945 - val_loss: 0.5012 - val_accuracy: 0.7796\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4348 - accuracy: 0.7933 - val_loss: 0.4909 - val_accuracy: 0.7806\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4317 - accuracy: 0.7922 - val_loss: 0.4948 - val_accuracy: 0.7796\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7806\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4302 - accuracy: 0.7948 - val_loss: 0.5026 - val_accuracy: 0.7714\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4330 - accuracy: 0.7930 - val_loss: 0.4946 - val_accuracy: 0.7796\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4288 - accuracy: 0.7938 - val_loss: 0.4915 - val_accuracy: 0.7827\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4303 - accuracy: 0.7956 - val_loss: 0.4953 - val_accuracy: 0.7796\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4369 - accuracy: 0.7933 - val_loss: 0.5046 - val_accuracy: 0.7724\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4383 - accuracy: 0.7853 - val_loss: 0.4937 - val_accuracy: 0.7816\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4302 - accuracy: 0.7910 - val_loss: 0.5026 - val_accuracy: 0.7806\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.4313 - accuracy: 0.7912 - val_loss: 0.5062 - val_accuracy: 0.7704\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.7961 - val_loss: 0.5080 - val_accuracy: 0.7765\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.7953 - val_loss: 0.4898 - val_accuracy: 0.7847\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.7935 - val_loss: 0.4973 - val_accuracy: 0.7837\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.7905 - val_loss: 0.5012 - val_accuracy: 0.7796\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7958 - val_loss: 0.4966 - val_accuracy: 0.7878\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4296 - accuracy: 0.7968 - val_loss: 0.4980 - val_accuracy: 0.7776\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7953 - val_loss: 0.4992 - val_accuracy: 0.7857\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7953 - val_loss: 0.4970 - val_accuracy: 0.7776\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7920 - val_loss: 0.4979 - val_accuracy: 0.7827\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4295 - accuracy: 0.7948 - val_loss: 0.5059 - val_accuracy: 0.7776\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.7897 - val_loss: 0.4922 - val_accuracy: 0.7816\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.4302 - accuracy: 0.7915 - val_loss: 0.4956 - val_accuracy: 0.7867\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.4303 - accuracy: 0.7925 - val_loss: 0.5015 - val_accuracy: 0.7847\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4335 - accuracy: 0.7961 - val_loss: 0.4976 - val_accuracy: 0.7755\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.4953 - val_accuracy: 0.7816\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.7961 - val_loss: 0.5010 - val_accuracy: 0.7837\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.7950 - val_loss: 0.4942 - val_accuracy: 0.7847\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.4274 - accuracy: 0.7979 - val_loss: 0.5004 - val_accuracy: 0.7806\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.4265 - accuracy: 0.7956 - val_loss: 0.5016 - val_accuracy: 0.7827\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4278 - accuracy: 0.7950 - val_loss: 0.4975 - val_accuracy: 0.7857\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.7920 - val_loss: 0.5020 - val_accuracy: 0.7765\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.7991 - val_loss: 0.4990 - val_accuracy: 0.7827\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7930 - val_loss: 0.4963 - val_accuracy: 0.7847\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.4288 - accuracy: 0.7958 - val_loss: 0.5008 - val_accuracy: 0.7806\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.4246 - accuracy: 0.7948 - val_loss: 0.5044 - val_accuracy: 0.7806\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4292 - accuracy: 0.7973 - val_loss: 0.4990 - val_accuracy: 0.7806\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.7897 - val_loss: 0.5044 - val_accuracy: 0.7837\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.7968 - val_loss: 0.5032 - val_accuracy: 0.7847\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.7910 - val_loss: 0.4979 - val_accuracy: 0.7827\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4346 - accuracy: 0.7892 - val_loss: 0.4959 - val_accuracy: 0.7765\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7991 - val_loss: 0.4977 - val_accuracy: 0.7827\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.7979 - val_loss: 0.5006 - val_accuracy: 0.7786\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.7966 - val_loss: 0.4972 - val_accuracy: 0.7898\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.7989 - val_loss: 0.5003 - val_accuracy: 0.7776\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7928 - val_loss: 0.5048 - val_accuracy: 0.7816\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7950 - val_loss: 0.4984 - val_accuracy: 0.7796\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.7981 - val_loss: 0.4920 - val_accuracy: 0.7857\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4250 - accuracy: 0.7961 - val_loss: 0.4997 - val_accuracy: 0.7857\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.7961 - val_loss: 0.5050 - val_accuracy: 0.7857\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.7979 - val_loss: 0.5003 - val_accuracy: 0.7755\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7989 - val_loss: 0.5037 - val_accuracy: 0.7704\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7765\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.7945 - val_loss: 0.5123 - val_accuracy: 0.7776\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7928 - val_loss: 0.5033 - val_accuracy: 0.7857\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.7976 - val_loss: 0.4957 - val_accuracy: 0.7867\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4241 - accuracy: 0.7981 - val_loss: 0.5013 - val_accuracy: 0.7847\n",
            "Test accuracy: 0.785\n",
            "Train accuracy: 0.798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model's predictions against our testing data\n",
        "import numpy as np\n",
        "Y_pred = np.round(model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJZovcy-faR7",
        "outputId": "0548244a-f65c-4cf5-e362-fc89c702bcf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the first 10 predicted values\n",
        "Y_pred[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkFsJGAhf3Vv",
        "outputId": "6d10016e-fd90-44f8-c3d2-b3230fa079d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model using our testing data\n",
        "loss, acc = model.evaluate(X_test, Y_test, verbose = 0)\n",
        "print('Test accuracy: %.3f' %acc)\n",
        "\n",
        "loss, acc = model.evaluate(X_train, Y_train, verbose = 0)\n",
        "print('Train accuracy: %.3f' %acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-Jft1gHgEy9",
        "outputId": "6f0cd507-03bb-42f4-fe67-524252670d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.785\n",
            "Train accuracy: 0.798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "rCIIM-htCiGR",
        "outputId": "0879e00f-0f6e-44a1-bb72-8dbaf869c02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start working with the red wine data\n",
        "red.info()\n",
        "red.head()\n",
        "red.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "WaCltA2dyLw-",
        "outputId": "2b7dc1b5-be12-4ccc-ec93-2a87d87becfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1599 non-null   float64\n",
            " 1   volatile acidity      1599 non-null   float64\n",
            " 2   citric acid           1599 non-null   float64\n",
            " 3   residual sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free sulfur dioxide   1599 non-null   float64\n",
            " 6   total sulfur dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "1594            6.2             0.600         0.08             2.0      0.090   \n",
              "1595            5.9             0.550         0.10             2.2      0.062   \n",
              "1596            6.3             0.510         0.13             2.3      0.076   \n",
              "1597            5.9             0.645         0.12             2.0      0.075   \n",
              "1598            6.0             0.310         0.47             3.6      0.067   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
              "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
              "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
              "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
              "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
              "\n",
              "      alcohol  quality  \n",
              "1594     10.5        5  \n",
              "1595     11.2        6  \n",
              "1596     11.0        6  \n",
              "1597     10.2        5  \n",
              "1598     11.0        6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5b55904-ecef-491b-bae3-e783c6c5ce37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.47</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.067</td>\n",
              "      <td>18.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.99549</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5b55904-ecef-491b-bae3-e783c6c5ce37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5b55904-ecef-491b-bae3-e783c6c5ce37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5b55904-ecef-491b-bae3-e783c6c5ce37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modify the red data as needed, create redX and redY\n",
        "red['winequality'] = [1 if x >= 6 else 0 for x in red['quality']]\n",
        "redX = red.drop(['quality', 'winequality'], axis = 1)\n",
        "redY = red['winequality']"
      ],
      "metadata": {
        "id": "w8U0deKGygXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the red data for testing and training\n",
        "from sklearn.model_selection import train_test_split\n",
        "redX_train, redX_test, redY_train, redY_test = train_test_split(redX, redY, test_size = 0.2)"
      ],
      "metadata": {
        "id": "nOhz-ilvzcom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardize the red data\n",
        "mm = MinMaxScaler()\n",
        "fit = mm.fit(redX_train)\n",
        "redX_train = fit.transform(redX_train)\n",
        "redX_test = fit.transform(redX_test)"
      ],
      "metadata": {
        "id": "REbC0Um7zZV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the neural network model for the red data\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(12, activation = 'relu', input_shape = (11,)))\n",
        "model.add(Dense(8, activation = 'relu'))\n",
        "model.add(Dense(4, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'tanh'))"
      ],
      "metadata": {
        "id": "xLtV8ukvz_rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## compile the model for the red wine data\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "opt = tf.keras.optimizers.experimental.AdamW(learning_rate = 0.01)\n",
        "#opt = keras.optimizers.Adam()\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "history = model.fit(redX_train, redY_train, epochs = 20, batch_size = 8, verbose = 1)\n",
        "\n",
        "# test the model using our testing data\n",
        "loss, acc = model.evaluate(redX_test, redY_test, verbose = 0)\n",
        "print('Test accuracy: %.3f' %acc)\n",
        "\n",
        "# test the model using our training data\n",
        "loss, acc = model.evaluate(redX_train, redY_train, verbose = 0)\n",
        "print('Train accuracy: %.3f' %acc)"
      ],
      "metadata": {
        "id": "X9rkz2vt0Nmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677af658-2a49-48b2-9af8-cf6037b876c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "160/160 [==============================] - 2s 6ms/step - loss: 0.7668 - accuracy: 0.5950\n",
            "Epoch 2/20\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.5591 - accuracy: 0.7091\n",
            "Epoch 3/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5402 - accuracy: 0.7373\n",
            "Epoch 4/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5382 - accuracy: 0.7373\n",
            "Epoch 5/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5266 - accuracy: 0.7506\n",
            "Epoch 6/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5399 - accuracy: 0.7287\n",
            "Epoch 7/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5233 - accuracy: 0.7435\n",
            "Epoch 8/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5196 - accuracy: 0.7475\n",
            "Epoch 9/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5335 - accuracy: 0.7435\n",
            "Epoch 10/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5274 - accuracy: 0.7498\n",
            "Epoch 11/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5281 - accuracy: 0.7342\n",
            "Epoch 12/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5323 - accuracy: 0.7318\n",
            "Epoch 13/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5252 - accuracy: 0.7412\n",
            "Epoch 14/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5187 - accuracy: 0.7514\n",
            "Epoch 15/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5141 - accuracy: 0.7498\n",
            "Epoch 16/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5268 - accuracy: 0.7490\n",
            "Epoch 17/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5158 - accuracy: 0.7522\n",
            "Epoch 18/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5164 - accuracy: 0.7459\n",
            "Epoch 19/20\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5165 - accuracy: 0.7514\n",
            "Epoch 20/20\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.5170 - accuracy: 0.7435\n",
            "Test accuracy: 0.725\n",
            "Train accuracy: 0.746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My notes:\n",
        "\n",
        "\n",
        "*   Adam seems to be the best optimizer, no matter which activation function or loss is being used\n",
        "*   More epochs do not always improve the results\n",
        "*   I have a hard time getting the model above 80% accuracy, no matter which combination of optimizer/activation function/number of layers I use\n",
        "*   Manually specifying the learning rate can have a huge impact\n",
        "*   Best results: 0.766 test, 0.773 train\n",
        "\n"
      ],
      "metadata": {
        "id": "Uxxv9NotUObf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the red wine model's predictions against our testing data\n",
        "import numpy as np\n",
        "redY_pred = np.round(model.predict(redX_test))\n",
        "redY_pred[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOI9cVaF0YzJ",
        "outputId": "5d43dd31-e57f-4f3b-e57f-8ac35c5fcad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for regression model instead of classification\n",
        "# load data\n",
        "import pandas as pd\n",
        "white = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep = ';')\n",
        "red = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep = ';')"
      ],
      "metadata": {
        "id": "oV4hPfnJp-sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = white.drop(['quality'], axis = 1)\n",
        "Y = white['quality']"
      ],
      "metadata": {
        "id": "xSqfrHzvqIqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data for training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "CdiNOIREqOhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardize dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mm = MinMaxScaler()\n",
        "fit = mm.fit(X_train)\n",
        "X_train = fit.transform(X_train)\n",
        "X_test = fit.transform(X_test)"
      ],
      "metadata": {
        "id": "PUgEfquzqWeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the neural network regression model\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation = 'relu', input_shape = (11,)))\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'relu'))"
      ],
      "metadata": {
        "id": "A5LUmKkqqY-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile regression model for the white wine data\n",
        "import tensorflow as tf\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
        "model.compile(loss = 'mae', optimizer = opt, metrics = ['mae'])\n",
        "history = model.fit(X_train, Y_train, epochs = 500, batch_size = 1024, verbose = 1, validation_data=(X_test, Y_test))\n",
        "\n",
        "loss, acc = model.evaluate(X_test, Y_test, verbose = 0)\n",
        "print('Test accuracy: %.3f' %acc)\n",
        "\n",
        "loss, acc = model.evaluate(X_train, Y_train, verbose = 0)\n",
        "print('Train accuracy: %.3f' %acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOuxEUGkqcYA",
        "outputId": "73d3de02-913d-4df6-8f5b-057c67c4d7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 2s 78ms/step - loss: 4.7482 - mae: 4.7482 - val_loss: 0.9396 - val_mae: 0.9396\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.1012 - mae: 2.1012 - val_loss: 0.9063 - val_mae: 0.9063\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.5475 - mae: 1.5475 - val_loss: 1.4280 - val_mae: 1.4280\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.1081 - mae: 1.1081 - val_loss: 1.4792 - val_mae: 1.4792\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0428 - mae: 1.0428 - val_loss: 1.0535 - val_mae: 1.0535\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0389 - mae: 1.0389 - val_loss: 0.7591 - val_mae: 0.7591\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8605 - mae: 0.8605 - val_loss: 0.8085 - val_mae: 0.8085\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7836 - mae: 0.7836 - val_loss: 0.8156 - val_mae: 0.8156\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7435 - mae: 0.7435 - val_loss: 0.8545 - val_mae: 0.8545\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7399 - mae: 0.7399 - val_loss: 0.7463 - val_mae: 0.7463\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7273 - mae: 0.7273 - val_loss: 0.7449 - val_mae: 0.7449\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7033 - mae: 0.7033 - val_loss: 0.6901 - val_mae: 0.6901\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6835 - mae: 0.6835 - val_loss: 0.6985 - val_mae: 0.6985\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6741 - mae: 0.6741 - val_loss: 0.6733 - val_mae: 0.6733\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6660 - mae: 0.6660 - val_loss: 0.6778 - val_mae: 0.6778\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6574 - mae: 0.6574 - val_loss: 0.6600 - val_mae: 0.6600\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6533 - mae: 0.6533 - val_loss: 0.6684 - val_mae: 0.6684\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6485 - mae: 0.6485 - val_loss: 0.6487 - val_mae: 0.6487\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6428 - mae: 0.6428 - val_loss: 0.6569 - val_mae: 0.6569\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6375 - mae: 0.6375 - val_loss: 0.6379 - val_mae: 0.6379\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6328 - mae: 0.6328 - val_loss: 0.6462 - val_mae: 0.6462\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6299 - mae: 0.6299 - val_loss: 0.6293 - val_mae: 0.6293\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6257 - mae: 0.6257 - val_loss: 0.6375 - val_mae: 0.6375\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6218 - mae: 0.6218 - val_loss: 0.6217 - val_mae: 0.6217\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6216 - mae: 0.6216 - val_loss: 0.6376 - val_mae: 0.6376\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6192 - mae: 0.6192 - val_loss: 0.6156 - val_mae: 0.6156\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6149 - mae: 0.6149 - val_loss: 0.6204 - val_mae: 0.6204\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6128 - mae: 0.6128 - val_loss: 0.6172 - val_mae: 0.6172\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6102 - mae: 0.6102 - val_loss: 0.6078 - val_mae: 0.6078\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6077 - mae: 0.6077 - val_loss: 0.6219 - val_mae: 0.6219\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6068 - mae: 0.6068 - val_loss: 0.6012 - val_mae: 0.6012\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6045 - mae: 0.6045 - val_loss: 0.6056 - val_mae: 0.6056\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6022 - mae: 0.6022 - val_loss: 0.6082 - val_mae: 0.6082\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6002 - mae: 0.6002 - val_loss: 0.5987 - val_mae: 0.5987\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5976 - mae: 0.5976 - val_loss: 0.5951 - val_mae: 0.5951\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5961 - mae: 0.5961 - val_loss: 0.5913 - val_mae: 0.5913\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5976 - mae: 0.5976 - val_loss: 0.5899 - val_mae: 0.5899\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5942 - mae: 0.5942 - val_loss: 0.6000 - val_mae: 0.6000\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5951 - mae: 0.5951 - val_loss: 0.6060 - val_mae: 0.6060\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5984 - mae: 0.5984 - val_loss: 0.5835 - val_mae: 0.5835\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5921 - mae: 0.5921 - val_loss: 0.5834 - val_mae: 0.5834\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5927 - mae: 0.5927 - val_loss: 0.5931 - val_mae: 0.5931\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5914 - mae: 0.5914 - val_loss: 0.5933 - val_mae: 0.5933\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5880 - mae: 0.5880 - val_loss: 0.6029 - val_mae: 0.6029\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5908 - mae: 0.5908 - val_loss: 0.5821 - val_mae: 0.5821\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5892 - mae: 0.5892 - val_loss: 0.5772 - val_mae: 0.5772\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5928 - mae: 0.5928 - val_loss: 0.6161 - val_mae: 0.6161\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5936 - mae: 0.5936 - val_loss: 0.5985 - val_mae: 0.5985\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5856 - mae: 0.5856 - val_loss: 0.5801 - val_mae: 0.5801\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5836 - mae: 0.5836 - val_loss: 0.5830 - val_mae: 0.5830\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5902 - mae: 0.5902 - val_loss: 0.5796 - val_mae: 0.5796\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5897 - mae: 0.5897 - val_loss: 0.5870 - val_mae: 0.5870\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5808 - mae: 0.5808 - val_loss: 0.5995 - val_mae: 0.5995\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5802 - mae: 0.5802 - val_loss: 0.5804 - val_mae: 0.5804\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5753 - mae: 0.5753 - val_loss: 0.5716 - val_mae: 0.5716\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5745 - mae: 0.5745 - val_loss: 0.5712 - val_mae: 0.5712\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5734 - mae: 0.5734 - val_loss: 0.5813 - val_mae: 0.5813\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5740 - mae: 0.5740 - val_loss: 0.5682 - val_mae: 0.5682\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5719 - mae: 0.5719 - val_loss: 0.5689 - val_mae: 0.5689\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5707 - mae: 0.5707 - val_loss: 0.5720 - val_mae: 0.5720\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5714 - mae: 0.5714 - val_loss: 0.5680 - val_mae: 0.5680\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5684 - mae: 0.5684 - val_loss: 0.5645 - val_mae: 0.5645\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5678 - mae: 0.5678 - val_loss: 0.5599 - val_mae: 0.5599\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5713 - mae: 0.5713 - val_loss: 0.5604 - val_mae: 0.5604\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5663 - mae: 0.5663 - val_loss: 0.5578 - val_mae: 0.5578\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5683 - mae: 0.5683 - val_loss: 0.5575 - val_mae: 0.5575\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5647 - mae: 0.5647 - val_loss: 0.5567 - val_mae: 0.5567\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5650 - mae: 0.5650 - val_loss: 0.5553 - val_mae: 0.5553\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5632 - mae: 0.5632 - val_loss: 0.5610 - val_mae: 0.5610\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5603 - mae: 0.5603 - val_loss: 0.5572 - val_mae: 0.5572\n",
            "Epoch 71/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5613 - mae: 0.5613 - val_loss: 0.5561 - val_mae: 0.5561\n",
            "Epoch 72/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5574 - mae: 0.5574 - val_loss: 0.5529 - val_mae: 0.5529\n",
            "Epoch 73/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5579 - mae: 0.5579 - val_loss: 0.5618 - val_mae: 0.5618\n",
            "Epoch 74/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5541 - mae: 0.5541 - val_loss: 0.5587 - val_mae: 0.5587\n",
            "Epoch 75/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5518 - mae: 0.5518 - val_loss: 0.5488 - val_mae: 0.5488\n",
            "Epoch 76/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5546 - mae: 0.5546 - val_loss: 0.5464 - val_mae: 0.5464\n",
            "Epoch 77/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5580 - mae: 0.5580 - val_loss: 0.5568 - val_mae: 0.5568\n",
            "Epoch 78/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5603 - mae: 0.5603 - val_loss: 0.5499 - val_mae: 0.5499\n",
            "Epoch 79/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5508 - mae: 0.5508 - val_loss: 0.5525 - val_mae: 0.5525\n",
            "Epoch 80/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5576 - mae: 0.5576 - val_loss: 0.5465 - val_mae: 0.5465\n",
            "Epoch 81/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5531 - mae: 0.5531 - val_loss: 0.5593 - val_mae: 0.5593\n",
            "Epoch 82/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5460 - mae: 0.5460 - val_loss: 0.5500 - val_mae: 0.5500\n",
            "Epoch 83/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5495 - mae: 0.5495 - val_loss: 0.5648 - val_mae: 0.5648\n",
            "Epoch 84/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5484 - mae: 0.5484 - val_loss: 0.5454 - val_mae: 0.5454\n",
            "Epoch 85/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5447 - mae: 0.5447 - val_loss: 0.5697 - val_mae: 0.5697\n",
            "Epoch 86/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5448 - mae: 0.5448 - val_loss: 0.5398 - val_mae: 0.5398\n",
            "Epoch 87/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5453 - mae: 0.5453 - val_loss: 0.5399 - val_mae: 0.5399\n",
            "Epoch 88/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5556 - mae: 0.5556 - val_loss: 0.5480 - val_mae: 0.5480\n",
            "Epoch 89/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5592 - mae: 0.5592 - val_loss: 0.5464 - val_mae: 0.5464\n",
            "Epoch 90/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5508 - mae: 0.5508 - val_loss: 0.5412 - val_mae: 0.5412\n",
            "Epoch 91/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5433 - mae: 0.5433 - val_loss: 0.5396 - val_mae: 0.5396\n",
            "Epoch 92/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5412 - mae: 0.5412 - val_loss: 0.5433 - val_mae: 0.5433\n",
            "Epoch 93/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5453 - mae: 0.5453 - val_loss: 0.5418 - val_mae: 0.5418\n",
            "Epoch 94/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5433 - mae: 0.5433 - val_loss: 0.5614 - val_mae: 0.5614\n",
            "Epoch 95/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5419 - mae: 0.5419 - val_loss: 0.6089 - val_mae: 0.6089\n",
            "Epoch 96/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5796 - mae: 0.5796 - val_loss: 0.5413 - val_mae: 0.5413\n",
            "Epoch 97/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5547 - mae: 0.5547 - val_loss: 0.5445 - val_mae: 0.5445\n",
            "Epoch 98/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5495 - mae: 0.5495 - val_loss: 0.5491 - val_mae: 0.5491\n",
            "Epoch 99/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5471 - mae: 0.5471 - val_loss: 0.5377 - val_mae: 0.5377\n",
            "Epoch 100/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5387 - mae: 0.5387 - val_loss: 0.5386 - val_mae: 0.5386\n",
            "Epoch 101/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5428 - mae: 0.5428 - val_loss: 0.5665 - val_mae: 0.5665\n",
            "Epoch 102/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5509 - mae: 0.5509 - val_loss: 0.5530 - val_mae: 0.5530\n",
            "Epoch 103/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5469 - mae: 0.5469 - val_loss: 0.5436 - val_mae: 0.5436\n",
            "Epoch 104/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5477 - mae: 0.5477 - val_loss: 0.5511 - val_mae: 0.5511\n",
            "Epoch 105/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5534 - mae: 0.5534 - val_loss: 0.5371 - val_mae: 0.5371\n",
            "Epoch 106/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5448 - mae: 0.5448 - val_loss: 0.5392 - val_mae: 0.5392\n",
            "Epoch 107/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5357 - mae: 0.5357 - val_loss: 0.5402 - val_mae: 0.5402\n",
            "Epoch 108/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5346 - mae: 0.5346 - val_loss: 0.6091 - val_mae: 0.6091\n",
            "Epoch 109/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5538 - mae: 0.5538 - val_loss: 0.5379 - val_mae: 0.5379\n",
            "Epoch 110/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5322 - mae: 0.5322 - val_loss: 0.5350 - val_mae: 0.5350\n",
            "Epoch 111/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5324 - mae: 0.5324 - val_loss: 0.5339 - val_mae: 0.5339\n",
            "Epoch 112/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5331 - mae: 0.5331 - val_loss: 0.5486 - val_mae: 0.5486\n",
            "Epoch 113/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5579 - mae: 0.5579 - val_loss: 0.5383 - val_mae: 0.5383\n",
            "Epoch 114/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5520 - mae: 0.5520 - val_loss: 0.5495 - val_mae: 0.5495\n",
            "Epoch 115/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5342 - mae: 0.5342 - val_loss: 0.5387 - val_mae: 0.5387\n",
            "Epoch 116/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5332 - mae: 0.5332 - val_loss: 0.5593 - val_mae: 0.5593\n",
            "Epoch 117/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5317 - mae: 0.5317 - val_loss: 0.5368 - val_mae: 0.5368\n",
            "Epoch 118/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5288 - mae: 0.5288 - val_loss: 0.5389 - val_mae: 0.5389\n",
            "Epoch 119/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5371 - mae: 0.5371 - val_loss: 0.5329 - val_mae: 0.5329\n",
            "Epoch 120/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5415 - mae: 0.5415 - val_loss: 0.5910 - val_mae: 0.5910\n",
            "Epoch 121/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5435 - mae: 0.5435 - val_loss: 0.5513 - val_mae: 0.5513\n",
            "Epoch 122/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5435 - mae: 0.5435 - val_loss: 0.5340 - val_mae: 0.5340\n",
            "Epoch 123/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5354 - mae: 0.5354 - val_loss: 0.5302 - val_mae: 0.5302\n",
            "Epoch 124/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5284 - mae: 0.5284 - val_loss: 0.5309 - val_mae: 0.5309\n",
            "Epoch 125/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5324 - mae: 0.5324 - val_loss: 0.5327 - val_mae: 0.5327\n",
            "Epoch 126/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5315 - mae: 0.5315 - val_loss: 0.5388 - val_mae: 0.5388\n",
            "Epoch 127/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5343 - mae: 0.5343 - val_loss: 0.5340 - val_mae: 0.5340\n",
            "Epoch 128/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5334 - mae: 0.5334 - val_loss: 0.5554 - val_mae: 0.5554\n",
            "Epoch 129/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5415 - mae: 0.5415 - val_loss: 0.5520 - val_mae: 0.5520\n",
            "Epoch 130/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5316 - mae: 0.5316 - val_loss: 0.5355 - val_mae: 0.5355\n",
            "Epoch 131/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5374 - mae: 0.5374 - val_loss: 0.5339 - val_mae: 0.5339\n",
            "Epoch 132/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5563 - mae: 0.5563 - val_loss: 0.5808 - val_mae: 0.5808\n",
            "Epoch 133/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5396 - mae: 0.5396 - val_loss: 0.5811 - val_mae: 0.5811\n",
            "Epoch 134/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5421 - mae: 0.5421 - val_loss: 0.5317 - val_mae: 0.5317\n",
            "Epoch 135/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5258 - mae: 0.5258 - val_loss: 0.5309 - val_mae: 0.5309\n",
            "Epoch 136/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5351 - mae: 0.5351 - val_loss: 0.5309 - val_mae: 0.5309\n",
            "Epoch 137/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5316 - mae: 0.5316 - val_loss: 0.5441 - val_mae: 0.5441\n",
            "Epoch 138/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5228 - mae: 0.5228 - val_loss: 0.5381 - val_mae: 0.5381\n",
            "Epoch 139/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5221 - mae: 0.5221 - val_loss: 0.5331 - val_mae: 0.5331\n",
            "Epoch 140/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5200 - mae: 0.5200 - val_loss: 0.5437 - val_mae: 0.5437\n",
            "Epoch 141/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5240 - mae: 0.5240 - val_loss: 0.5278 - val_mae: 0.5278\n",
            "Epoch 142/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5224 - mae: 0.5224 - val_loss: 0.5348 - val_mae: 0.5348\n",
            "Epoch 143/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5187 - mae: 0.5187 - val_loss: 0.5329 - val_mae: 0.5329\n",
            "Epoch 144/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5185 - mae: 0.5185 - val_loss: 0.5289 - val_mae: 0.5289\n",
            "Epoch 145/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5255 - mae: 0.5255 - val_loss: 0.5455 - val_mae: 0.5455\n",
            "Epoch 146/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5193 - mae: 0.5193 - val_loss: 0.5310 - val_mae: 0.5310\n",
            "Epoch 147/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5196 - mae: 0.5196 - val_loss: 0.5440 - val_mae: 0.5440\n",
            "Epoch 148/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5229 - mae: 0.5229 - val_loss: 0.5480 - val_mae: 0.5480\n",
            "Epoch 149/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5432 - mae: 0.5432 - val_loss: 0.5541 - val_mae: 0.5541\n",
            "Epoch 150/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5253 - mae: 0.5253 - val_loss: 0.5432 - val_mae: 0.5432\n",
            "Epoch 151/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5196 - mae: 0.5196 - val_loss: 0.5256 - val_mae: 0.5256\n",
            "Epoch 152/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5205 - mae: 0.5205 - val_loss: 0.5462 - val_mae: 0.5462\n",
            "Epoch 153/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5299 - mae: 0.5299 - val_loss: 0.5325 - val_mae: 0.5325\n",
            "Epoch 154/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5222 - mae: 0.5222 - val_loss: 0.5281 - val_mae: 0.5281\n",
            "Epoch 155/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5176 - mae: 0.5176 - val_loss: 0.5802 - val_mae: 0.5802\n",
            "Epoch 156/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5314 - mae: 0.5314 - val_loss: 0.5424 - val_mae: 0.5424\n",
            "Epoch 157/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5406 - mae: 0.5406 - val_loss: 0.5286 - val_mae: 0.5286\n",
            "Epoch 158/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5317 - mae: 0.5317 - val_loss: 0.5483 - val_mae: 0.5483\n",
            "Epoch 159/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5203 - mae: 0.5203 - val_loss: 0.5300 - val_mae: 0.5300\n",
            "Epoch 160/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5188 - mae: 0.5188 - val_loss: 0.5233 - val_mae: 0.5233\n",
            "Epoch 161/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5186 - mae: 0.5186 - val_loss: 0.5287 - val_mae: 0.5287\n",
            "Epoch 162/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5162 - mae: 0.5162 - val_loss: 0.5358 - val_mae: 0.5358\n",
            "Epoch 163/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5142 - mae: 0.5142 - val_loss: 0.5333 - val_mae: 0.5333\n",
            "Epoch 164/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5242 - mae: 0.5242 - val_loss: 0.5512 - val_mae: 0.5512\n",
            "Epoch 165/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5520 - mae: 0.5520 - val_loss: 0.5391 - val_mae: 0.5391\n",
            "Epoch 166/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5265 - mae: 0.5265 - val_loss: 0.5477 - val_mae: 0.5477\n",
            "Epoch 167/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5180 - mae: 0.5180 - val_loss: 0.5249 - val_mae: 0.5249\n",
            "Epoch 168/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5336 - mae: 0.5336 - val_loss: 0.5862 - val_mae: 0.5862\n",
            "Epoch 169/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5558 - mae: 0.5558 - val_loss: 0.5290 - val_mae: 0.5290\n",
            "Epoch 170/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5438 - mae: 0.5438 - val_loss: 0.5969 - val_mae: 0.5969\n",
            "Epoch 171/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5609 - mae: 0.5609 - val_loss: 0.5363 - val_mae: 0.5363\n",
            "Epoch 172/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5290 - mae: 0.5290 - val_loss: 0.5323 - val_mae: 0.5323\n",
            "Epoch 173/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5187 - mae: 0.5187 - val_loss: 0.5708 - val_mae: 0.5708\n",
            "Epoch 174/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5302 - mae: 0.5302 - val_loss: 0.5371 - val_mae: 0.5371\n",
            "Epoch 175/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5293 - mae: 0.5293 - val_loss: 0.5276 - val_mae: 0.5276\n",
            "Epoch 176/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5267 - mae: 0.5267 - val_loss: 0.5942 - val_mae: 0.5942\n",
            "Epoch 177/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5238 - mae: 0.5238 - val_loss: 0.5255 - val_mae: 0.5255\n",
            "Epoch 178/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5104 - mae: 0.5104 - val_loss: 0.5441 - val_mae: 0.5441\n",
            "Epoch 179/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5116 - mae: 0.5116 - val_loss: 0.5263 - val_mae: 0.5263\n",
            "Epoch 180/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5072 - mae: 0.5072 - val_loss: 0.5270 - val_mae: 0.5270\n",
            "Epoch 181/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5200 - mae: 0.5200 - val_loss: 0.5468 - val_mae: 0.5468\n",
            "Epoch 182/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5143 - mae: 0.5143 - val_loss: 0.5250 - val_mae: 0.5250\n",
            "Epoch 183/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5129 - mae: 0.5129 - val_loss: 0.5362 - val_mae: 0.5362\n",
            "Epoch 184/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5194 - mae: 0.5194 - val_loss: 0.5415 - val_mae: 0.5415\n",
            "Epoch 185/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5145 - mae: 0.5145 - val_loss: 0.5262 - val_mae: 0.5262\n",
            "Epoch 186/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5195 - mae: 0.5195 - val_loss: 0.5463 - val_mae: 0.5463\n",
            "Epoch 187/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5198 - mae: 0.5198 - val_loss: 0.5758 - val_mae: 0.5758\n",
            "Epoch 188/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5360 - mae: 0.5360 - val_loss: 0.5239 - val_mae: 0.5239\n",
            "Epoch 189/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5253 - mae: 0.5253 - val_loss: 0.5272 - val_mae: 0.5272\n",
            "Epoch 190/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5171 - mae: 0.5171 - val_loss: 0.5398 - val_mae: 0.5398\n",
            "Epoch 191/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5109 - mae: 0.5109 - val_loss: 0.5549 - val_mae: 0.5549\n",
            "Epoch 192/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5159 - mae: 0.5159 - val_loss: 0.5297 - val_mae: 0.5297\n",
            "Epoch 193/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5147 - mae: 0.5147 - val_loss: 0.5265 - val_mae: 0.5265\n",
            "Epoch 194/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5061 - mae: 0.5061 - val_loss: 0.5438 - val_mae: 0.5438\n",
            "Epoch 195/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5179 - mae: 0.5179 - val_loss: 0.5314 - val_mae: 0.5314\n",
            "Epoch 196/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5207 - mae: 0.5207 - val_loss: 0.5385 - val_mae: 0.5385\n",
            "Epoch 197/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5176 - mae: 0.5176 - val_loss: 0.5533 - val_mae: 0.5533\n",
            "Epoch 198/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5158 - mae: 0.5158 - val_loss: 0.5284 - val_mae: 0.5284\n",
            "Epoch 199/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5113 - mae: 0.5113 - val_loss: 0.5215 - val_mae: 0.5215\n",
            "Epoch 200/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5077 - mae: 0.5077 - val_loss: 0.5654 - val_mae: 0.5654\n",
            "Epoch 201/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5273 - mae: 0.5273 - val_loss: 0.5471 - val_mae: 0.5471\n",
            "Epoch 202/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5289 - mae: 0.5289 - val_loss: 0.5621 - val_mae: 0.5621\n",
            "Epoch 203/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5445 - mae: 0.5445 - val_loss: 0.5497 - val_mae: 0.5497\n",
            "Epoch 204/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5300 - mae: 0.5300 - val_loss: 0.5252 - val_mae: 0.5252\n",
            "Epoch 205/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5159 - mae: 0.5159 - val_loss: 0.5418 - val_mae: 0.5418\n",
            "Epoch 206/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5170 - mae: 0.5170 - val_loss: 0.5525 - val_mae: 0.5525\n",
            "Epoch 207/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5299 - mae: 0.5299 - val_loss: 0.5286 - val_mae: 0.5286\n",
            "Epoch 208/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5287 - mae: 0.5287 - val_loss: 0.5776 - val_mae: 0.5776\n",
            "Epoch 209/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5503 - mae: 0.5503 - val_loss: 0.5784 - val_mae: 0.5784\n",
            "Epoch 210/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5556 - mae: 0.5556 - val_loss: 0.5332 - val_mae: 0.5332\n",
            "Epoch 211/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5787 - mae: 0.5787 - val_loss: 0.5584 - val_mae: 0.5584\n",
            "Epoch 212/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6029 - mae: 0.6029 - val_loss: 0.5684 - val_mae: 0.5684\n",
            "Epoch 213/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5758 - mae: 0.5758 - val_loss: 0.5883 - val_mae: 0.5883\n",
            "Epoch 214/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5557 - mae: 0.5557 - val_loss: 0.5549 - val_mae: 0.5549\n",
            "Epoch 215/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5362 - mae: 0.5362 - val_loss: 0.5403 - val_mae: 0.5403\n",
            "Epoch 216/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5302 - mae: 0.5302 - val_loss: 0.5360 - val_mae: 0.5360\n",
            "Epoch 217/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5275 - mae: 0.5275 - val_loss: 0.5359 - val_mae: 0.5359\n",
            "Epoch 218/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5199 - mae: 0.5199 - val_loss: 0.5296 - val_mae: 0.5296\n",
            "Epoch 219/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5165 - mae: 0.5165 - val_loss: 0.5529 - val_mae: 0.5529\n",
            "Epoch 220/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5346 - mae: 0.5346 - val_loss: 0.5286 - val_mae: 0.5286\n",
            "Epoch 221/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5170 - mae: 0.5170 - val_loss: 0.5223 - val_mae: 0.5223\n",
            "Epoch 222/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5115 - mae: 0.5115 - val_loss: 0.5270 - val_mae: 0.5270\n",
            "Epoch 223/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5139 - mae: 0.5139 - val_loss: 0.5336 - val_mae: 0.5336\n",
            "Epoch 224/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5046 - mae: 0.5046 - val_loss: 0.5428 - val_mae: 0.5428\n",
            "Epoch 225/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5055 - mae: 0.5055 - val_loss: 0.5400 - val_mae: 0.5400\n",
            "Epoch 226/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5051 - mae: 0.5051 - val_loss: 0.5345 - val_mae: 0.5345\n",
            "Epoch 227/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5039 - mae: 0.5039 - val_loss: 0.5230 - val_mae: 0.5230\n",
            "Epoch 228/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5030 - mae: 0.5030 - val_loss: 0.5248 - val_mae: 0.5248\n",
            "Epoch 229/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5079 - mae: 0.5079 - val_loss: 0.5243 - val_mae: 0.5243\n",
            "Epoch 230/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5061 - mae: 0.5061 - val_loss: 0.5313 - val_mae: 0.5313\n",
            "Epoch 231/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5079 - mae: 0.5079 - val_loss: 0.5725 - val_mae: 0.5725\n",
            "Epoch 232/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5157 - mae: 0.5157 - val_loss: 0.5593 - val_mae: 0.5593\n",
            "Epoch 233/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5116 - mae: 0.5116 - val_loss: 0.5414 - val_mae: 0.5414\n",
            "Epoch 234/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5111 - mae: 0.5111 - val_loss: 0.5230 - val_mae: 0.5230\n",
            "Epoch 235/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5036 - mae: 0.5036 - val_loss: 0.5448 - val_mae: 0.5448\n",
            "Epoch 236/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5311 - mae: 0.5311 - val_loss: 0.5233 - val_mae: 0.5233\n",
            "Epoch 237/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5246 - mae: 0.5246 - val_loss: 0.5230 - val_mae: 0.5230\n",
            "Epoch 238/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5334 - mae: 0.5334 - val_loss: 0.5231 - val_mae: 0.5231\n",
            "Epoch 239/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5363 - mae: 0.5363 - val_loss: 0.5300 - val_mae: 0.5300\n",
            "Epoch 240/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5168 - mae: 0.5168 - val_loss: 0.5407 - val_mae: 0.5407\n",
            "Epoch 241/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5017 - mae: 0.5017 - val_loss: 0.5437 - val_mae: 0.5437\n",
            "Epoch 242/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4986 - mae: 0.4986 - val_loss: 0.5240 - val_mae: 0.5240\n",
            "Epoch 243/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4945 - mae: 0.4945 - val_loss: 0.5215 - val_mae: 0.5215\n",
            "Epoch 244/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4976 - mae: 0.4976 - val_loss: 0.5211 - val_mae: 0.5211\n",
            "Epoch 245/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5018 - mae: 0.5018 - val_loss: 0.5260 - val_mae: 0.5260\n",
            "Epoch 246/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4978 - mae: 0.4978 - val_loss: 0.5380 - val_mae: 0.5380\n",
            "Epoch 247/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4955 - mae: 0.4955 - val_loss: 0.5246 - val_mae: 0.5246\n",
            "Epoch 248/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4900 - mae: 0.4900 - val_loss: 0.5196 - val_mae: 0.5196\n",
            "Epoch 249/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4948 - mae: 0.4948 - val_loss: 0.5481 - val_mae: 0.5481\n",
            "Epoch 250/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5095 - mae: 0.5095 - val_loss: 0.5226 - val_mae: 0.5226\n",
            "Epoch 251/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4985 - mae: 0.4985 - val_loss: 0.5246 - val_mae: 0.5246\n",
            "Epoch 252/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5195 - mae: 0.5195 - val_loss: 0.5297 - val_mae: 0.5297\n",
            "Epoch 253/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5017 - mae: 0.5017 - val_loss: 0.5669 - val_mae: 0.5669\n",
            "Epoch 254/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5006 - mae: 0.5006 - val_loss: 0.5280 - val_mae: 0.5280\n",
            "Epoch 255/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4946 - mae: 0.4946 - val_loss: 0.5237 - val_mae: 0.5237\n",
            "Epoch 256/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5031 - mae: 0.5031 - val_loss: 0.5382 - val_mae: 0.5382\n",
            "Epoch 257/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4914 - mae: 0.4914 - val_loss: 0.5412 - val_mae: 0.5412\n",
            "Epoch 258/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4946 - mae: 0.4946 - val_loss: 0.5258 - val_mae: 0.5258\n",
            "Epoch 259/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4895 - mae: 0.4895 - val_loss: 0.5192 - val_mae: 0.5192\n",
            "Epoch 260/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5021 - mae: 0.5021 - val_loss: 0.5205 - val_mae: 0.5205\n",
            "Epoch 261/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5114 - mae: 0.5114 - val_loss: 0.5522 - val_mae: 0.5522\n",
            "Epoch 262/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4939 - mae: 0.4939 - val_loss: 0.5548 - val_mae: 0.5548\n",
            "Epoch 263/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5057 - mae: 0.5057 - val_loss: 0.5190 - val_mae: 0.5190\n",
            "Epoch 264/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4956 - mae: 0.4956 - val_loss: 0.5179 - val_mae: 0.5179\n",
            "Epoch 265/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4867 - mae: 0.4867 - val_loss: 0.5190 - val_mae: 0.5190\n",
            "Epoch 266/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4860 - mae: 0.4860 - val_loss: 0.5273 - val_mae: 0.5273\n",
            "Epoch 267/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5007 - mae: 0.5007 - val_loss: 0.5343 - val_mae: 0.5343\n",
            "Epoch 268/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4884 - mae: 0.4884 - val_loss: 0.5360 - val_mae: 0.5360\n",
            "Epoch 269/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5093 - mae: 0.5093 - val_loss: 0.5272 - val_mae: 0.5272\n",
            "Epoch 270/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5161 - mae: 0.5161 - val_loss: 0.5809 - val_mae: 0.5809\n",
            "Epoch 271/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5026 - mae: 0.5026 - val_loss: 0.5226 - val_mae: 0.5226\n",
            "Epoch 272/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4885 - mae: 0.4885 - val_loss: 0.5298 - val_mae: 0.5298\n",
            "Epoch 273/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4870 - mae: 0.4870 - val_loss: 0.5193 - val_mae: 0.5193\n",
            "Epoch 274/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4845 - mae: 0.4845 - val_loss: 0.5249 - val_mae: 0.5249\n",
            "Epoch 275/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4905 - mae: 0.4905 - val_loss: 0.5497 - val_mae: 0.5497\n",
            "Epoch 276/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4878 - mae: 0.4878 - val_loss: 0.5394 - val_mae: 0.5394\n",
            "Epoch 277/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4905 - mae: 0.4905 - val_loss: 0.5288 - val_mae: 0.5288\n",
            "Epoch 278/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4923 - mae: 0.4923 - val_loss: 0.5354 - val_mae: 0.5354\n",
            "Epoch 279/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4856 - mae: 0.4856 - val_loss: 0.5245 - val_mae: 0.5245\n",
            "Epoch 280/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4899 - mae: 0.4899 - val_loss: 0.5290 - val_mae: 0.5290\n",
            "Epoch 281/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4849 - mae: 0.4849 - val_loss: 0.5248 - val_mae: 0.5248\n",
            "Epoch 282/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4881 - mae: 0.4881 - val_loss: 0.5314 - val_mae: 0.5314\n",
            "Epoch 283/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4819 - mae: 0.4819 - val_loss: 0.5224 - val_mae: 0.5224\n",
            "Epoch 284/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4885 - mae: 0.4885 - val_loss: 0.5719 - val_mae: 0.5719\n",
            "Epoch 285/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4937 - mae: 0.4937 - val_loss: 0.5295 - val_mae: 0.5295\n",
            "Epoch 286/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4969 - mae: 0.4969 - val_loss: 0.5253 - val_mae: 0.5253\n",
            "Epoch 287/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4883 - mae: 0.4883 - val_loss: 0.5679 - val_mae: 0.5679\n",
            "Epoch 288/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5000 - mae: 0.5000 - val_loss: 0.5205 - val_mae: 0.5205\n",
            "Epoch 289/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5143 - mae: 0.5143 - val_loss: 0.5496 - val_mae: 0.5496\n",
            "Epoch 290/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5164 - mae: 0.5164 - val_loss: 0.5411 - val_mae: 0.5411\n",
            "Epoch 291/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4905 - mae: 0.4905 - val_loss: 0.5666 - val_mae: 0.5666\n",
            "Epoch 292/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4929 - mae: 0.4929 - val_loss: 0.5234 - val_mae: 0.5234\n",
            "Epoch 293/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4906 - mae: 0.4906 - val_loss: 0.5212 - val_mae: 0.5212\n",
            "Epoch 294/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4809 - mae: 0.4809 - val_loss: 0.5292 - val_mae: 0.5292\n",
            "Epoch 295/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4776 - mae: 0.4776 - val_loss: 0.5183 - val_mae: 0.5183\n",
            "Epoch 296/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4768 - mae: 0.4768 - val_loss: 0.5166 - val_mae: 0.5166\n",
            "Epoch 297/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4835 - mae: 0.4835 - val_loss: 0.5599 - val_mae: 0.5599\n",
            "Epoch 298/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4887 - mae: 0.4887 - val_loss: 0.5203 - val_mae: 0.5203\n",
            "Epoch 299/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4820 - mae: 0.4820 - val_loss: 0.5351 - val_mae: 0.5351\n",
            "Epoch 300/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4797 - mae: 0.4797 - val_loss: 0.5213 - val_mae: 0.5213\n",
            "Epoch 301/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4796 - mae: 0.4796 - val_loss: 0.5294 - val_mae: 0.5294\n",
            "Epoch 302/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4788 - mae: 0.4788 - val_loss: 0.5255 - val_mae: 0.5255\n",
            "Epoch 303/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4880 - mae: 0.4880 - val_loss: 0.5451 - val_mae: 0.5451\n",
            "Epoch 304/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4916 - mae: 0.4916 - val_loss: 0.5228 - val_mae: 0.5228\n",
            "Epoch 305/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4938 - mae: 0.4938 - val_loss: 0.5282 - val_mae: 0.5282\n",
            "Epoch 306/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4924 - mae: 0.4924 - val_loss: 0.5202 - val_mae: 0.5202\n",
            "Epoch 307/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4838 - mae: 0.4838 - val_loss: 0.5192 - val_mae: 0.5192\n",
            "Epoch 308/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4852 - mae: 0.4852 - val_loss: 0.5183 - val_mae: 0.5183\n",
            "Epoch 309/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4777 - mae: 0.4777 - val_loss: 0.5445 - val_mae: 0.5445\n",
            "Epoch 310/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4817 - mae: 0.4817 - val_loss: 0.5560 - val_mae: 0.5560\n",
            "Epoch 311/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4809 - mae: 0.4809 - val_loss: 0.5223 - val_mae: 0.5223\n",
            "Epoch 312/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4807 - mae: 0.4807 - val_loss: 0.5582 - val_mae: 0.5582\n",
            "Epoch 313/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4966 - mae: 0.4966 - val_loss: 0.5275 - val_mae: 0.5275\n",
            "Epoch 314/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4985 - mae: 0.4985 - val_loss: 0.5380 - val_mae: 0.5380\n",
            "Epoch 315/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5021 - mae: 0.5021 - val_loss: 0.5867 - val_mae: 0.5867\n",
            "Epoch 316/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5230 - mae: 0.5230 - val_loss: 0.5733 - val_mae: 0.5733\n",
            "Epoch 317/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5062 - mae: 0.5062 - val_loss: 0.5236 - val_mae: 0.5236\n",
            "Epoch 318/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4881 - mae: 0.4881 - val_loss: 0.5350 - val_mae: 0.5350\n",
            "Epoch 319/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5014 - mae: 0.5014 - val_loss: 0.5319 - val_mae: 0.5319\n",
            "Epoch 320/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4885 - mae: 0.4885 - val_loss: 0.5698 - val_mae: 0.5698\n",
            "Epoch 321/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4875 - mae: 0.4875 - val_loss: 0.5233 - val_mae: 0.5233\n",
            "Epoch 322/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4879 - mae: 0.4879 - val_loss: 0.5274 - val_mae: 0.5274\n",
            "Epoch 323/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4976 - mae: 0.4976 - val_loss: 0.5508 - val_mae: 0.5508\n",
            "Epoch 324/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4933 - mae: 0.4933 - val_loss: 0.5165 - val_mae: 0.5165\n",
            "Epoch 325/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4753 - mae: 0.4753 - val_loss: 0.5151 - val_mae: 0.5151\n",
            "Epoch 326/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4807 - mae: 0.4807 - val_loss: 0.5862 - val_mae: 0.5862\n",
            "Epoch 327/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5088 - mae: 0.5088 - val_loss: 0.6154 - val_mae: 0.6154\n",
            "Epoch 328/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5213 - mae: 0.5213 - val_loss: 0.5306 - val_mae: 0.5306\n",
            "Epoch 329/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4980 - mae: 0.4980 - val_loss: 0.5168 - val_mae: 0.5168\n",
            "Epoch 330/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4839 - mae: 0.4839 - val_loss: 0.5247 - val_mae: 0.5247\n",
            "Epoch 331/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4844 - mae: 0.4844 - val_loss: 0.5218 - val_mae: 0.5218\n",
            "Epoch 332/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4793 - mae: 0.4793 - val_loss: 0.5437 - val_mae: 0.5437\n",
            "Epoch 333/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4898 - mae: 0.4898 - val_loss: 0.5249 - val_mae: 0.5249\n",
            "Epoch 334/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4880 - mae: 0.4880 - val_loss: 0.5307 - val_mae: 0.5307\n",
            "Epoch 335/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4884 - mae: 0.4884 - val_loss: 0.5261 - val_mae: 0.5261\n",
            "Epoch 336/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4777 - mae: 0.4777 - val_loss: 0.5966 - val_mae: 0.5966\n",
            "Epoch 337/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5000 - mae: 0.5000 - val_loss: 0.5214 - val_mae: 0.5214\n",
            "Epoch 338/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4823 - mae: 0.4823 - val_loss: 0.5180 - val_mae: 0.5180\n",
            "Epoch 339/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4764 - mae: 0.4764 - val_loss: 0.5676 - val_mae: 0.5676\n",
            "Epoch 340/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5011 - mae: 0.5011 - val_loss: 0.5768 - val_mae: 0.5768\n",
            "Epoch 341/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5182 - mae: 0.5182 - val_loss: 0.5264 - val_mae: 0.5264\n",
            "Epoch 342/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5127 - mae: 0.5127 - val_loss: 0.5197 - val_mae: 0.5197\n",
            "Epoch 343/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4842 - mae: 0.4842 - val_loss: 0.5256 - val_mae: 0.5256\n",
            "Epoch 344/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4866 - mae: 0.4866 - val_loss: 0.5191 - val_mae: 0.5191\n",
            "Epoch 345/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4947 - mae: 0.4947 - val_loss: 0.5250 - val_mae: 0.5250\n",
            "Epoch 346/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4841 - mae: 0.4841 - val_loss: 0.5386 - val_mae: 0.5386\n",
            "Epoch 347/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4742 - mae: 0.4742 - val_loss: 0.5187 - val_mae: 0.5187\n",
            "Epoch 348/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4733 - mae: 0.4733 - val_loss: 0.5246 - val_mae: 0.5246\n",
            "Epoch 349/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4902 - mae: 0.4902 - val_loss: 0.5494 - val_mae: 0.5494\n",
            "Epoch 350/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4852 - mae: 0.4852 - val_loss: 0.5419 - val_mae: 0.5419\n",
            "Epoch 351/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4940 - mae: 0.4940 - val_loss: 0.5148 - val_mae: 0.5148\n",
            "Epoch 352/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4846 - mae: 0.4846 - val_loss: 0.5175 - val_mae: 0.5175\n",
            "Epoch 353/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4724 - mae: 0.4724 - val_loss: 0.5158 - val_mae: 0.5158\n",
            "Epoch 354/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4673 - mae: 0.4673 - val_loss: 0.5260 - val_mae: 0.5260\n",
            "Epoch 355/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4728 - mae: 0.4728 - val_loss: 0.5191 - val_mae: 0.5191\n",
            "Epoch 356/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4715 - mae: 0.4715 - val_loss: 0.5171 - val_mae: 0.5171\n",
            "Epoch 357/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4606 - mae: 0.4606 - val_loss: 0.5169 - val_mae: 0.5169\n",
            "Epoch 358/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4632 - mae: 0.4632 - val_loss: 0.5394 - val_mae: 0.5394\n",
            "Epoch 359/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4705 - mae: 0.4705 - val_loss: 0.5166 - val_mae: 0.5166\n",
            "Epoch 360/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4713 - mae: 0.4713 - val_loss: 0.5259 - val_mae: 0.5259\n",
            "Epoch 361/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4644 - mae: 0.4644 - val_loss: 0.5176 - val_mae: 0.5176\n",
            "Epoch 362/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4657 - mae: 0.4657 - val_loss: 0.5168 - val_mae: 0.5168\n",
            "Epoch 363/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4804 - mae: 0.4804 - val_loss: 0.5524 - val_mae: 0.5524\n",
            "Epoch 364/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4841 - mae: 0.4841 - val_loss: 0.5178 - val_mae: 0.5178\n",
            "Epoch 365/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4705 - mae: 0.4705 - val_loss: 0.5187 - val_mae: 0.5187\n",
            "Epoch 366/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4581 - mae: 0.4581 - val_loss: 0.5199 - val_mae: 0.5199\n",
            "Epoch 367/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4648 - mae: 0.4648 - val_loss: 0.5591 - val_mae: 0.5591\n",
            "Epoch 368/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4734 - mae: 0.4734 - val_loss: 0.5171 - val_mae: 0.5171\n",
            "Epoch 369/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4614 - mae: 0.4614 - val_loss: 0.5273 - val_mae: 0.5273\n",
            "Epoch 370/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4566 - mae: 0.4566 - val_loss: 0.5251 - val_mae: 0.5251\n",
            "Epoch 371/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4546 - mae: 0.4546 - val_loss: 0.5174 - val_mae: 0.5174\n",
            "Epoch 372/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4607 - mae: 0.4607 - val_loss: 0.5239 - val_mae: 0.5239\n",
            "Epoch 373/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4727 - mae: 0.4727 - val_loss: 0.5184 - val_mae: 0.5184\n",
            "Epoch 374/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4704 - mae: 0.4704 - val_loss: 0.5595 - val_mae: 0.5595\n",
            "Epoch 375/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4669 - mae: 0.4669 - val_loss: 0.5204 - val_mae: 0.5204\n",
            "Epoch 376/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4648 - mae: 0.4648 - val_loss: 0.5344 - val_mae: 0.5344\n",
            "Epoch 377/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4766 - mae: 0.4766 - val_loss: 0.5208 - val_mae: 0.5208\n",
            "Epoch 378/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4813 - mae: 0.4813 - val_loss: 0.5278 - val_mae: 0.5278\n",
            "Epoch 379/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4795 - mae: 0.4795 - val_loss: 0.5415 - val_mae: 0.5415\n",
            "Epoch 380/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4763 - mae: 0.4763 - val_loss: 0.5259 - val_mae: 0.5259\n",
            "Epoch 381/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4654 - mae: 0.4654 - val_loss: 0.5243 - val_mae: 0.5243\n",
            "Epoch 382/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4727 - mae: 0.4727 - val_loss: 0.5342 - val_mae: 0.5342\n",
            "Epoch 383/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4626 - mae: 0.4626 - val_loss: 0.5178 - val_mae: 0.5178\n",
            "Epoch 384/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4641 - mae: 0.4641 - val_loss: 0.5226 - val_mae: 0.5226\n",
            "Epoch 385/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4584 - mae: 0.4584 - val_loss: 0.5160 - val_mae: 0.5160\n",
            "Epoch 386/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4624 - mae: 0.4624 - val_loss: 0.5304 - val_mae: 0.5304\n",
            "Epoch 387/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4700 - mae: 0.4700 - val_loss: 0.5205 - val_mae: 0.5205\n",
            "Epoch 388/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4653 - mae: 0.4653 - val_loss: 0.5475 - val_mae: 0.5475\n",
            "Epoch 389/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4732 - mae: 0.4732 - val_loss: 0.5188 - val_mae: 0.5188\n",
            "Epoch 390/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4598 - mae: 0.4598 - val_loss: 0.5332 - val_mae: 0.5332\n",
            "Epoch 391/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4646 - mae: 0.4646 - val_loss: 0.5183 - val_mae: 0.5183\n",
            "Epoch 392/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4688 - mae: 0.4688 - val_loss: 0.5236 - val_mae: 0.5236\n",
            "Epoch 393/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4750 - mae: 0.4750 - val_loss: 0.5259 - val_mae: 0.5259\n",
            "Epoch 394/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4807 - mae: 0.4807 - val_loss: 0.5971 - val_mae: 0.5971\n",
            "Epoch 395/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4880 - mae: 0.4880 - val_loss: 0.5183 - val_mae: 0.5183\n",
            "Epoch 396/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4581 - mae: 0.4581 - val_loss: 0.5127 - val_mae: 0.5127\n",
            "Epoch 397/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4509 - mae: 0.4509 - val_loss: 0.5153 - val_mae: 0.5153\n",
            "Epoch 398/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4558 - mae: 0.4558 - val_loss: 0.5262 - val_mae: 0.5262\n",
            "Epoch 399/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4612 - mae: 0.4612 - val_loss: 0.5298 - val_mae: 0.5298\n",
            "Epoch 400/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4546 - mae: 0.4546 - val_loss: 0.5211 - val_mae: 0.5211\n",
            "Epoch 401/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4486 - mae: 0.4486 - val_loss: 0.5370 - val_mae: 0.5370\n",
            "Epoch 402/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4631 - mae: 0.4631 - val_loss: 0.5158 - val_mae: 0.5158\n",
            "Epoch 403/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4578 - mae: 0.4578 - val_loss: 0.5440 - val_mae: 0.5440\n",
            "Epoch 404/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4598 - mae: 0.4598 - val_loss: 0.5212 - val_mae: 0.5212\n",
            "Epoch 405/500\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4554 - mae: 0.4554 - val_loss: 0.5207 - val_mae: 0.5207\n",
            "Epoch 406/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4510 - mae: 0.4510 - val_loss: 0.5168 - val_mae: 0.5168\n",
            "Epoch 407/500\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.4651 - mae: 0.4651 - val_loss: 0.5497 - val_mae: 0.5497\n",
            "Epoch 408/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4644 - mae: 0.4644 - val_loss: 0.5199 - val_mae: 0.5199\n",
            "Epoch 409/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4636 - mae: 0.4636 - val_loss: 0.5222 - val_mae: 0.5222\n",
            "Epoch 410/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4528 - mae: 0.4528 - val_loss: 0.5195 - val_mae: 0.5195\n",
            "Epoch 411/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4614 - mae: 0.4614 - val_loss: 0.5231 - val_mae: 0.5231\n",
            "Epoch 412/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4685 - mae: 0.4685 - val_loss: 0.5432 - val_mae: 0.5432\n",
            "Epoch 413/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4677 - mae: 0.4677 - val_loss: 0.5269 - val_mae: 0.5269\n",
            "Epoch 414/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4910 - mae: 0.4910 - val_loss: 0.5174 - val_mae: 0.5174\n",
            "Epoch 415/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4948 - mae: 0.4948 - val_loss: 0.5503 - val_mae: 0.5503\n",
            "Epoch 416/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4734 - mae: 0.4734 - val_loss: 0.5786 - val_mae: 0.5786\n",
            "Epoch 417/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4838 - mae: 0.4838 - val_loss: 0.5112 - val_mae: 0.5112\n",
            "Epoch 418/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4592 - mae: 0.4592 - val_loss: 0.5262 - val_mae: 0.5262\n",
            "Epoch 419/500\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4883 - mae: 0.4883 - val_loss: 0.5350 - val_mae: 0.5350\n",
            "Epoch 420/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4777 - mae: 0.4777 - val_loss: 0.5978 - val_mae: 0.5978\n",
            "Epoch 421/500\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4806 - mae: 0.4806 - val_loss: 0.5202 - val_mae: 0.5202\n",
            "Epoch 422/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4595 - mae: 0.4595 - val_loss: 0.5585 - val_mae: 0.5585\n",
            "Epoch 423/500\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4899 - mae: 0.4899 - val_loss: 0.5458 - val_mae: 0.5458\n",
            "Epoch 424/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4754 - mae: 0.4754 - val_loss: 0.5122 - val_mae: 0.5122\n",
            "Epoch 425/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4639 - mae: 0.4639 - val_loss: 0.5231 - val_mae: 0.5231\n",
            "Epoch 426/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4616 - mae: 0.4616 - val_loss: 0.5329 - val_mae: 0.5329\n",
            "Epoch 427/500\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4689 - mae: 0.4689 - val_loss: 0.5167 - val_mae: 0.5167\n",
            "Epoch 428/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4516 - mae: 0.4516 - val_loss: 0.5100 - val_mae: 0.5100\n",
            "Epoch 429/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4467 - mae: 0.4467 - val_loss: 0.5300 - val_mae: 0.5300\n",
            "Epoch 430/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4652 - mae: 0.4652 - val_loss: 0.5193 - val_mae: 0.5193\n",
            "Epoch 431/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4511 - mae: 0.4511 - val_loss: 0.5130 - val_mae: 0.5130\n",
            "Epoch 432/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4463 - mae: 0.4463 - val_loss: 0.5204 - val_mae: 0.5204\n",
            "Epoch 433/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4512 - mae: 0.4512 - val_loss: 0.5206 - val_mae: 0.5206\n",
            "Epoch 434/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4452 - mae: 0.4452 - val_loss: 0.5162 - val_mae: 0.5162\n",
            "Epoch 435/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4404 - mae: 0.4404 - val_loss: 0.5198 - val_mae: 0.5198\n",
            "Epoch 436/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4540 - mae: 0.4540 - val_loss: 0.5192 - val_mae: 0.5192\n",
            "Epoch 437/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4485 - mae: 0.4485 - val_loss: 0.5188 - val_mae: 0.5188\n",
            "Epoch 438/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4466 - mae: 0.4466 - val_loss: 0.5239 - val_mae: 0.5239\n",
            "Epoch 439/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4603 - mae: 0.4603 - val_loss: 0.5301 - val_mae: 0.5301\n",
            "Epoch 440/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4547 - mae: 0.4547 - val_loss: 0.5236 - val_mae: 0.5236\n",
            "Epoch 441/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4753 - mae: 0.4753 - val_loss: 0.5264 - val_mae: 0.5264\n",
            "Epoch 442/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4665 - mae: 0.4665 - val_loss: 0.5947 - val_mae: 0.5947\n",
            "Epoch 443/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4805 - mae: 0.4805 - val_loss: 0.5309 - val_mae: 0.5309\n",
            "Epoch 444/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4727 - mae: 0.4727 - val_loss: 0.5318 - val_mae: 0.5318\n",
            "Epoch 445/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4738 - mae: 0.4738 - val_loss: 0.5374 - val_mae: 0.5374\n",
            "Epoch 446/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4817 - mae: 0.4817 - val_loss: 0.5299 - val_mae: 0.5299\n",
            "Epoch 447/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4690 - mae: 0.4690 - val_loss: 0.5780 - val_mae: 0.5780\n",
            "Epoch 448/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4826 - mae: 0.4826 - val_loss: 0.5336 - val_mae: 0.5336\n",
            "Epoch 449/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4831 - mae: 0.4831 - val_loss: 0.5141 - val_mae: 0.5141\n",
            "Epoch 450/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4722 - mae: 0.4722 - val_loss: 0.5728 - val_mae: 0.5728\n",
            "Epoch 451/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5024 - mae: 0.5024 - val_loss: 0.5771 - val_mae: 0.5771\n",
            "Epoch 452/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4983 - mae: 0.4983 - val_loss: 0.5555 - val_mae: 0.5555\n",
            "Epoch 453/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4897 - mae: 0.4897 - val_loss: 0.5528 - val_mae: 0.5528\n",
            "Epoch 454/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4908 - mae: 0.4908 - val_loss: 0.5493 - val_mae: 0.5493\n",
            "Epoch 455/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4875 - mae: 0.4875 - val_loss: 0.5519 - val_mae: 0.5519\n",
            "Epoch 456/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4971 - mae: 0.4971 - val_loss: 0.5838 - val_mae: 0.5838\n",
            "Epoch 457/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5186 - mae: 0.5186 - val_loss: 0.5317 - val_mae: 0.5317\n",
            "Epoch 458/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4907 - mae: 0.4907 - val_loss: 0.5194 - val_mae: 0.5194\n",
            "Epoch 459/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4731 - mae: 0.4731 - val_loss: 0.5208 - val_mae: 0.5208\n",
            "Epoch 460/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4668 - mae: 0.4668 - val_loss: 0.5429 - val_mae: 0.5429\n",
            "Epoch 461/500\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4740 - mae: 0.4740 - val_loss: 0.5373 - val_mae: 0.5373\n",
            "Epoch 462/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4651 - mae: 0.4651 - val_loss: 0.5270 - val_mae: 0.5270\n",
            "Epoch 463/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4568 - mae: 0.4568 - val_loss: 0.5124 - val_mae: 0.5124\n",
            "Epoch 464/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4454 - mae: 0.4454 - val_loss: 0.5134 - val_mae: 0.5134\n",
            "Epoch 465/500\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4423 - mae: 0.4423 - val_loss: 0.5135 - val_mae: 0.5135\n",
            "Epoch 466/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4398 - mae: 0.4398 - val_loss: 0.5113 - val_mae: 0.5113\n",
            "Epoch 467/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4405 - mae: 0.4405 - val_loss: 0.5157 - val_mae: 0.5157\n",
            "Epoch 468/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4494 - mae: 0.4494 - val_loss: 0.5362 - val_mae: 0.5362\n",
            "Epoch 469/500\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4471 - mae: 0.4471 - val_loss: 0.5184 - val_mae: 0.5184\n",
            "Epoch 470/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4371 - mae: 0.4371 - val_loss: 0.5174 - val_mae: 0.5174\n",
            "Epoch 471/500\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4378 - mae: 0.4378 - val_loss: 0.5397 - val_mae: 0.5397\n",
            "Epoch 472/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4544 - mae: 0.4544 - val_loss: 0.5207 - val_mae: 0.5207\n",
            "Epoch 473/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4576 - mae: 0.4576 - val_loss: 0.5423 - val_mae: 0.5423\n",
            "Epoch 474/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4616 - mae: 0.4616 - val_loss: 0.5167 - val_mae: 0.5167\n",
            "Epoch 475/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4499 - mae: 0.4499 - val_loss: 0.5273 - val_mae: 0.5273\n",
            "Epoch 476/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4465 - mae: 0.4465 - val_loss: 0.5422 - val_mae: 0.5422\n",
            "Epoch 477/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4588 - mae: 0.4588 - val_loss: 0.5164 - val_mae: 0.5164\n",
            "Epoch 478/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4384 - mae: 0.4384 - val_loss: 0.5109 - val_mae: 0.5109\n",
            "Epoch 479/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4326 - mae: 0.4326 - val_loss: 0.5141 - val_mae: 0.5141\n",
            "Epoch 480/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4418 - mae: 0.4418 - val_loss: 0.5186 - val_mae: 0.5186\n",
            "Epoch 481/500\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4445 - mae: 0.4445 - val_loss: 0.5112 - val_mae: 0.5112\n",
            "Epoch 482/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4383 - mae: 0.4383 - val_loss: 0.5482 - val_mae: 0.5482\n",
            "Epoch 483/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4445 - mae: 0.4445 - val_loss: 0.5202 - val_mae: 0.5202\n",
            "Epoch 484/500\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4593 - mae: 0.4593 - val_loss: 0.5255 - val_mae: 0.5255\n",
            "Epoch 485/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4464 - mae: 0.4464 - val_loss: 0.5636 - val_mae: 0.5636\n",
            "Epoch 486/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4548 - mae: 0.4548 - val_loss: 0.5156 - val_mae: 0.5156\n",
            "Epoch 487/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4420 - mae: 0.4420 - val_loss: 0.5182 - val_mae: 0.5182\n",
            "Epoch 488/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4346 - mae: 0.4346 - val_loss: 0.5393 - val_mae: 0.5393\n",
            "Epoch 489/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4400 - mae: 0.4400 - val_loss: 0.5182 - val_mae: 0.5182\n",
            "Epoch 490/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4356 - mae: 0.4356 - val_loss: 0.5320 - val_mae: 0.5320\n",
            "Epoch 491/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4348 - mae: 0.4348 - val_loss: 0.5150 - val_mae: 0.5150\n",
            "Epoch 492/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4308 - mae: 0.4308 - val_loss: 0.5194 - val_mae: 0.5194\n",
            "Epoch 493/500\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4295 - mae: 0.4295 - val_loss: 0.5157 - val_mae: 0.5157\n",
            "Epoch 494/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4351 - mae: 0.4351 - val_loss: 0.5152 - val_mae: 0.5152\n",
            "Epoch 495/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4283 - mae: 0.4283 - val_loss: 0.5350 - val_mae: 0.5350\n",
            "Epoch 496/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4397 - mae: 0.4397 - val_loss: 0.5218 - val_mae: 0.5218\n",
            "Epoch 497/500\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4351 - mae: 0.4351 - val_loss: 0.5380 - val_mae: 0.5380\n",
            "Epoch 498/500\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4323 - mae: 0.4323 - val_loss: 0.5122 - val_mae: 0.5122\n",
            "Epoch 499/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4394 - mae: 0.4394 - val_loss: 0.5201 - val_mae: 0.5201\n",
            "Epoch 500/500\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4490 - mae: 0.4490 - val_loss: 0.5264 - val_mae: 0.5264\n",
            "Test accuracy: 0.526\n",
            "Train accuracy: 0.460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['mae'])\n",
        "plt.plot(history.history['val_mae'])\n",
        "plt.title('regression model accuracy')\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "NpPZq4g8bzGA",
        "outputId": "21020aad-5bdc-49f2-ecb6-784ca9b19282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}